{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ae409",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BatteryMind - Resource Usage Analysis Notebook\n",
    "\n",
    "Comprehensive resource usage analysis for BatteryMind AI models including\n",
    "CPU, GPU, memory, and disk usage patterns during training and inference.\n",
    "\n",
    "This notebook provides:\n",
    "- CPU utilization monitoring\n",
    "- GPU utilization and memory tracking\n",
    "- System memory usage analysis\n",
    "- Disk I/O performance monitoring\n",
    "- Network usage for distributed training\n",
    "- Power consumption estimation\n",
    "- Resource optimization recommendations\n",
    "\n",
    "Author: BatteryMind Development Team\n",
    "Version: 1.0.0\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import threading\n",
    "import queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU monitoring\n",
    "try:\n",
    "    import GPUtil\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    GPU_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"GPU monitoring not available\")\n",
    "\n",
    "# System monitoring\n",
    "import platform\n",
    "import socket\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Model imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from transformers.battery_health_predictor.trainer import BatteryHealthTrainer\n",
    "from transformers.degradation_forecaster.trainer import DegradationTrainer\n",
    "from reinforcement_learning.training.rl_trainer import RLTrainer\n",
    "from federated_learning.server.federated_server import FederatedServer\n",
    "\n",
    "# Utility imports\n",
    "from utils.data_utils import generate_training_data\n",
    "from utils.model_utils import get_model_size\n",
    "from utils.visualization import plot_resource_usage\n",
    "\n",
    "print(\"BatteryMind Resource Usage Analysis Notebook\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# System Information\n",
    "print(f\"System: {platform.system()} {platform.release()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "print(f\"CPU Cores: {psutil.cpu_count()}\")\n",
    "print(f\"Total Memory: {psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    gpu_count = pynvml.nvmlDeviceGetCount()\n",
    "    print(f\"GPU Count: {gpu_count}\")\n",
    "    for i in range(gpu_count):\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')\n",
    "        print(f\"GPU {i}: {name}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "class ResourceMonitor:\n",
    "    \"\"\"\n",
    "    Comprehensive resource monitoring system for BatteryMind AI training and inference.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitoring_interval=1.0):\n",
    "        self.monitoring_interval = monitoring_interval\n",
    "        self.monitoring_active = False\n",
    "        self.resource_data = []\n",
    "        self.monitoring_thread = None\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Start resource monitoring in a separate thread.\"\"\"\n",
    "        self.monitoring_active = True\n",
    "        self.resource_data = []\n",
    "        self.monitoring_thread = threading.Thread(target=self._monitor_resources)\n",
    "        self.monitoring_thread.daemon = True\n",
    "        self.monitoring_thread.start()\n",
    "        print(\"Resource monitoring started\")\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"Stop resource monitoring.\"\"\"\n",
    "        self.monitoring_active = False\n",
    "        if self.monitoring_thread:\n",
    "            self.monitoring_thread.join()\n",
    "        print(\"Resource monitoring stopped\")\n",
    "    \n",
    "    def _monitor_resources(self):\n",
    "        \"\"\"Monitor system resources continuously.\"\"\"\n",
    "        while self.monitoring_active:\n",
    "            timestamp = time.time()\n",
    "            \n",
    "            # CPU monitoring\n",
    "            cpu_percent = psutil.cpu_percent(interval=None)\n",
    "            cpu_freq = psutil.cpu_freq()\n",
    "            \n",
    "            # Memory monitoring\n",
    "            memory = psutil.virtual_memory()\n",
    "            swap = psutil.swap_memory()\n",
    "            \n",
    "            # Disk I/O monitoring\n",
    "            disk_io = psutil.disk_io_counters()\n",
    "            \n",
    "            # Network monitoring\n",
    "            network_io = psutil.net_io_counters()\n",
    "            \n",
    "            # Process-specific monitoring\n",
    "            process = psutil.Process()\n",
    "            process_info = process.as_dict(attrs=['pid', 'memory_info', 'cpu_percent', 'num_threads'])\n",
    "            \n",
    "            resource_entry = {\n",
    "                'timestamp': timestamp,\n",
    "                'cpu_percent': cpu_percent,\n",
    "                'cpu_freq_current': cpu_freq.current if cpu_freq else 0,\n",
    "                'memory_total': memory.total,\n",
    "                'memory_used': memory.used,\n",
    "                'memory_percent': memory.percent,\n",
    "                'swap_used': swap.used,\n",
    "                'swap_percent': swap.percent,\n",
    "                'disk_read_bytes': disk_io.read_bytes if disk_io else 0,\n",
    "                'disk_write_bytes': disk_io.write_bytes if disk_io else 0,\n",
    "                'network_sent_bytes': network_io.bytes_sent if network_io else 0,\n",
    "                'network_recv_bytes': network_io.bytes_recv if network_io else 0,\n",
    "                'process_memory_rss': process_info['memory_info'].rss,\n",
    "                'process_memory_vms': process_info['memory_info'].vms,\n",
    "                'process_cpu_percent': process_info['cpu_percent'],\n",
    "                'process_num_threads': process_info['num_threads']\n",
    "            }\n",
    "            \n",
    "            # GPU monitoring if available\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    gpu_info = self._get_gpu_info()\n",
    "                    resource_entry.update(gpu_info)\n",
    "                except Exception as e:\n",
    "                    print(f\"GPU monitoring error: {e}\")\n",
    "            \n",
    "            self.resource_data.append(resource_entry)\n",
    "            time.sleep(self.monitoring_interval)\n",
    "    \n",
    "    def _get_gpu_info(self):\n",
    "        \"\"\"Get GPU information and utilization.\"\"\"\n",
    "        gpu_info = {}\n",
    "        \n",
    "        try:\n",
    "            gpu_count = pynvml.nvmlDeviceGetCount()\n",
    "            \n",
    "            for i in range(gpu_count):\n",
    "                handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "                \n",
    "                # GPU utilization\n",
    "                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                \n",
    "                # Memory info\n",
    "                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                \n",
    "                # Temperature\n",
    "                temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)\n",
    "                \n",
    "                # Power consumption\n",
    "                power = pynvml.nvmlDeviceGetPowerUsage(handle)\n",
    "                \n",
    "                gpu_info[f'gpu_{i}_utilization'] = utilization.gpu\n",
    "                gpu_info[f'gpu_{i}_memory_used'] = memory_info.used\n",
    "                gpu_info[f'gpu_{i}_memory_total'] = memory_info.total\n",
    "                gpu_info[f'gpu_{i}_memory_percent'] = (memory_info.used / memory_info.total) * 100\n",
    "                gpu_info[f'gpu_{i}_temperature'] = temp\n",
    "                gpu_info[f'gpu_{i}_power_usage'] = power / 1000  # Convert to watts\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting GPU info: {e}\")\n",
    "        \n",
    "        return gpu_info\n",
    "    \n",
    "    def get_resource_summary(self):\n",
    "        \"\"\"Get summary statistics of resource usage.\"\"\"\n",
    "        if not self.resource_data:\n",
    "            return {}\n",
    "        \n",
    "        df = pd.DataFrame(self.resource_data)\n",
    "        \n",
    "        summary = {\n",
    "            'duration_seconds': df['timestamp'].max() - df['timestamp'].min(),\n",
    "            'avg_cpu_percent': df['cpu_percent'].mean(),\n",
    "            'max_cpu_percent': df['cpu_percent'].max(),\n",
    "            'avg_memory_percent': df['memory_percent'].mean(),\n",
    "            'max_memory_percent': df['memory_percent'].max(),\n",
    "            'avg_process_memory_gb': df['process_memory_rss'].mean() / (1024**3),\n",
    "            'max_process_memory_gb': df['process_memory_rss'].max() / (1024**3),\n",
    "            'total_disk_read_gb': (df['disk_read_bytes'].max() - df['disk_read_bytes'].min()) / (1024**3),\n",
    "            'total_disk_write_gb': (df['disk_write_bytes'].max() - df['disk_write_bytes'].min()) / (1024**3),\n",
    "            'total_network_sent_gb': (df['network_sent_bytes'].max() - df['network_sent_bytes'].min()) / (1024**3),\n",
    "            'total_network_recv_gb': (df['network_recv_bytes'].max() - df['network_recv_bytes'].min()) / (1024**3)\n",
    "        }\n",
    "        \n",
    "        # GPU statistics if available\n",
    "        if GPU_AVAILABLE:\n",
    "            gpu_columns = [col for col in df.columns if col.startswith('gpu_')]\n",
    "            for col in gpu_columns:\n",
    "                if 'utilization' in col:\n",
    "                    summary[f'avg_{col}'] = df[col].mean()\n",
    "                    summary[f'max_{col}'] = df[col].max()\n",
    "                elif 'memory_percent' in col:\n",
    "                    summary[f'avg_{col}'] = df[col].mean()\n",
    "                    summary[f'max_{col}'] = df[col].max()\n",
    "                elif 'temperature' in col:\n",
    "                    summary[f'avg_{col}'] = df[col].mean()\n",
    "                    summary[f'max_{col}'] = df[col].max()\n",
    "                elif 'power_usage' in col:\n",
    "                    summary[f'avg_{col}'] = df[col].mean()\n",
    "                    summary[f'max_{col}'] = df[col].max()\n",
    "        \n",
    "        return summary\n",
    "\n",
    "class ModelResourceAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze resource usage for different BatteryMind models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.monitor = ResourceMonitor()\n",
    "        self.analysis_results = {}\n",
    "        \n",
    "    def analyze_transformer_training(self, epochs=5, batch_size=32):\n",
    "        \"\"\"Analyze resource usage during transformer model training.\"\"\"\n",
    "        print(\"Analyzing transformer training resource usage...\")\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = BatteryHealthTrainer()\n",
    "        \n",
    "        # Generate training data\n",
    "        train_data = generate_training_data(samples=1000, sequence_length=1000)\n",
    "        \n",
    "        # Start monitoring\n",
    "        self.monitor.start_monitoring()\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            start_time = time.time()\n",
    "            trainer.train(train_data, epochs=epochs, batch_size=batch_size)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Stop monitoring\n",
    "            self.monitor.stop_monitoring()\n",
    "            \n",
    "            # Get results\n",
    "            resource_summary = self.monitor.get_resource_summary()\n",
    "            resource_summary['training_time'] = end_time - start_time\n",
    "            resource_summary['model_type'] = 'transformer'\n",
    "            resource_summary['epochs'] = epochs\n",
    "            resource_summary['batch_size'] = batch_size\n",
    "            \n",
    "            self.analysis_results['transformer_training'] = resource_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during transformer training analysis: {e}\")\n",
    "            self.monitor.stop_monitoring()\n",
    "        \n",
    "        return resource_summary\n",
    "    \n",
    "    def analyze_rl_training(self, episodes=1000):\n",
    "        \"\"\"Analyze resource usage during RL agent training.\"\"\"\n",
    "        print(\"Analyzing RL training resource usage...\")\n",
    "        \n",
    "        # Initialize RL trainer\n",
    "        trainer = RLTrainer()\n",
    "        \n",
    "        # Start monitoring\n",
    "        self.monitor.start_monitoring()\n",
    "        \n",
    "        try:\n",
    "            # Train RL agent\n",
    "            start_time = time.time()\n",
    "            trainer.train(total_episodes=episodes)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Stop monitoring\n",
    "            self.monitor.stop_monitoring()\n",
    "            \n",
    "            # Get results\n",
    "            resource_summary = self.monitor.get_resource_summary()\n",
    "            resource_summary['training_time'] = end_time - start_time\n",
    "            resource_summary['model_type'] = 'rl_agent'\n",
    "            resource_summary['episodes'] = episodes\n",
    "            \n",
    "            self.analysis_results['rl_training'] = resource_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during RL training analysis: {e}\")\n",
    "            self.monitor.stop_monitoring()\n",
    "        \n",
    "        return resource_summary\n",
    "    \n",
    "    def analyze_federated_training(self, rounds=10, clients=5):\n",
    "        \"\"\"Analyze resource usage during federated learning.\"\"\"\n",
    "        print(\"Analyzing federated learning resource usage...\")\n",
    "        \n",
    "        # Initialize federated server\n",
    "        server = FederatedServer()\n",
    "        \n",
    "        # Start monitoring\n",
    "        self.monitor.start_monitoring()\n",
    "        \n",
    "        try:\n",
    "            # Run federated training\n",
    "            start_time = time.time()\n",
    "            server.run_federated_training(rounds=rounds, num_clients=clients)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Stop monitoring\n",
    "            self.monitor.stop_monitoring()\n",
    "            \n",
    "            # Get results\n",
    "            resource_summary = self.monitor.get_resource_summary()\n",
    "            resource_summary['training_time'] = end_time - start_time\n",
    "            resource_summary['model_type'] = 'federated'\n",
    "            resource_summary['rounds'] = rounds\n",
    "            resource_summary['clients'] = clients\n",
    "            \n",
    "            self.analysis_results['federated_training'] = resource_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during federated training analysis: {e}\")\n",
    "            self.monitor.stop_monitoring()\n",
    "        \n",
    "        return resource_summary\n",
    "    \n",
    "    def analyze_inference_resource_usage(self, model_type, batch_sizes=[1, 8, 32, 128]):\n",
    "        \"\"\"Analyze resource usage during inference.\"\"\"\n",
    "        print(f\"Analyzing {model_type} inference resource usage...\")\n",
    "        \n",
    "        # Load model based on type\n",
    "        if model_type == 'transformer':\n",
    "            from transformers.battery_health_predictor.predictor import BatteryHealthPredictor\n",
    "            model = BatteryHealthPredictor.load_model(\n",
    "                '../../model-artifacts/trained_models/transformer_v1.0/model.pkl'\n",
    "            )\n",
    "        elif model_type == 'rl_agent':\n",
    "            from reinforcement_learning.agents.charging_agent import ChargingAgent\n",
    "            model = ChargingAgent.load_model(\n",
    "                '../../model-artifacts/trained_models/rl_agent_v1.0/policy_network.pt'\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Unsupported model type: {model_type}\")\n",
    "            return {}\n",
    "        \n",
    "        inference_results = {}\n",
    "        \n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Testing batch size: {batch_size}\")\n",
    "            \n",
    "            # Generate test data\n",
    "            if model_type == 'transformer':\n",
    "                test_data = np.random.randn(batch_size, 1000, 10)\n",
    "            else:  # RL agent\n",
    "                test_data = np.random.randn(batch_size, 20)\n",
    "            \n",
    "            # Start monitoring\n",
    "            self.monitor.start_monitoring()\n",
    "            \n",
    "            try:\n",
    "                # Run inference multiple times\n",
    "                start_time = time.time()\n",
    "                for _ in range(100):\n",
    "                    _ = model.predict(test_data)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Stop monitoring\n",
    "                self.monitor.stop_monitoring()\n",
    "                \n",
    "                # Get results\n",
    "                resource_summary = self.monitor.get_resource_summary()\n",
    "                resource_summary['inference_time'] = end_time - start_time\n",
    "                resource_summary['model_type'] = model_type\n",
    "                resource_summary['batch_size'] = batch_size\n",
    "                resource_summary['num_inferences'] = 100\n",
    "                \n",
    "                inference_results[f'batch_{batch_size}'] = resource_summary\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during inference analysis: {e}\")\n",
    "                self.monitor.stop_monitoring()\n",
    "        \n",
    "        self.analysis_results[f'{model_type}_inference'] = inference_results\n",
    "        return inference_results\n",
    "    \n",
    "    def compare_model_resource_usage(self):\n",
    "        \"\"\"Compare resource usage across different models.\"\"\"\n",
    "        print(\"Comparing resource usage across models...\")\n",
    "        \n",
    "        comparison_data = []\n",
    "        \n",
    "        for analysis_name, results in self.analysis_results.items():\n",
    "            if isinstance(results, dict) and 'model_type' in results:\n",
    "                comparison_data.append({\n",
    "                    'analysis_type': analysis_name,\n",
    "                    'model_type': results['model_type'],\n",
    "                    'avg_cpu_percent': results.get('avg_cpu_percent', 0),\n",
    "                    'max_cpu_percent': results.get('max_cpu_percent', 0),\n",
    "                    'avg_memory_percent': results.get('avg_memory_percent', 0),\n",
    "                    'max_memory_percent': results.get('max_memory_percent', 0),\n",
    "                    'avg_process_memory_gb': results.get('avg_process_memory_gb', 0),\n",
    "                    'max_process_memory_gb': results.get('max_process_memory_gb', 0),\n",
    "                    'duration_seconds': results.get('duration_seconds', 0),\n",
    "                    'training_time': results.get('training_time', 0)\n",
    "                })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        return comparison_df\n",
    "    \n",
    "    def visualize_resource_usage(self):\n",
    "        \"\"\"Create visualizations of resource usage analysis.\"\"\"\n",
    "        print(\"Creating resource usage visualizations...\")\n",
    "        \n",
    "        # Set up plotting style\n",
    "        plt.style.use('seaborn-v0_8')\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. CPU Usage Comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        self._plot_cpu_usage_comparison(ax1)\n",
    "        ax1.set_title('CPU Usage Comparison')\n",
    "        ax1.set_xlabel('Model Type')\n",
    "        ax1.set_ylabel('CPU Usage (%)')\n",
    "        \n",
    "        # 2. Memory Usage Comparison\n",
    "        ax2 = axes[0, 1]\n",
    "        self._plot_memory_usage_comparison(ax2)\n",
    "        ax2.set_title('Memory Usage Comparison')\n",
    "        ax2.set_xlabel('Model Type')\n",
    "        ax2.set_ylabel('Memory Usage (GB)')\n",
    "        \n",
    "        # 3. Training Time Comparison\n",
    "        ax3 = axes[1, 0]\n",
    "        self._plot_training_time_comparison(ax3)\n",
    "        ax3.set_title('Training Time Comparison')\n",
    "        ax3.set_xlabel('Model Type')\n",
    "        ax3.set_ylabel('Training Time (seconds)')\n",
    "        \n",
    "        # 4. Resource Efficiency\n",
    "        ax4 = axes[1, 1]\n",
    "        self._plot_resource_efficiency(ax4)\n",
    "        ax4.set_title('Resource Efficiency')\n",
    "        ax4.set_xlabel('Model Type')\n",
    "        ax4.set_ylabel('Efficiency Score')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('resource_usage_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_cpu_usage_comparison(self, ax):\n",
    "        \"\"\"Plot CPU usage comparison.\"\"\"\n",
    "        model_types = []\n",
    "        cpu_usage = []\n",
    "        \n",
    "        for analysis_name, results in self.analysis_results.items():\n",
    "            if isinstance(results, dict) and 'model_type' in results:\n",
    "                model_types.append(results['model_type'])\n",
    "                cpu_usage.append(results.get('avg_cpu_percent', 0))\n",
    "        \n",
    "        if model_types:\n",
    "            ax.bar(model_types, cpu_usage)\n",
    "            ax.set_xticklabels(model_types, rotation=45, ha='right')\n",
    "    \n",
    "    def _plot_memory_usage_comparison(self, ax):\n",
    "        \"\"\"Plot memory usage comparison.\"\"\"\n",
    "        model_types = []\n",
    "        memory_usage = []\n",
    "        \n",
    "        for analysis_name, results in self.analysis_results.items():\n",
    "            if isinstance(results, dict) and 'model_type' in results:\n",
    "                model_types.append(results['model_type'])\n",
    "                memory_usage.append(results.get('avg_process_memory_gb', 0))\n",
    "        \n",
    "        if model_types:\n",
    "            ax.bar(model_types, memory_usage)\n",
    "            ax.set_xticklabels(model_types, rotation=45, ha='right')\n",
    "    \n",
    "    def _plot_training_time_comparison(self, ax):\n",
    "        \"\"\"Plot training time comparison.\"\"\"\n",
    "        model_types = []\n",
    "        training_times = []\n",
    "        \n",
    "        for analysis_name, results in self.analysis_results.items():\n",
    "            if isinstance(results, dict) and 'training_time' in results:\n",
    "                model_types.append(results['model_type'])\n",
    "                training_times.append(results['training_time'])\n",
    "        \n",
    "        if model_types:\n",
    "            ax.bar(model_types, training_times)\n",
    "            ax.set_xticklabels(model_types, rotation=45, ha='right')\n",
    "    \n",
    "    def _plot_resource_efficiency(self, ax):\n",
    "        \"\"\"Plot resource efficiency score.\"\"\"\n",
    "        model_types = []\n",
    "        efficiency_scores = []\n",
    "        \n",
    "        for analysis_name, results in self.analysis_results.items():\n",
    "            if isinstance(results, dict) and 'model_type' in results:\n",
    "                # Calculate efficiency score (lower is better)\n",
    "                cpu_score = results.get('avg_cpu_percent', 100) / 100\n",
    "                memory_score = results.get('avg_process_memory_gb', 10) / 10\n",
    "                time_score = results.get('training_time', 3600) / 3600\n",
    "                \n",
    "                efficiency_score = 1 / (cpu_score + memory_score + time_score)\n",
    "                \n",
    "                model_types.append(results['model_type'])\n",
    "                efficiency_scores.append(efficiency_score)\n",
    "        \n",
    "        if model_types:\n",
    "            ax.bar(model_types, efficiency_scores)\n",
    "            ax.set_xticklabels(model_types, rotation=45, ha='right')\n",
    "    \n",
    "    def generate_resource_report(self):\n",
    "        \"\"\"Generate comprehensive resource usage report.\"\"\"\n",
    "        print(\"Generating resource usage report...\")\n",
    "        \n",
    "        report = {\n",
    "            'system_info': {\n",
    "                'platform': platform.system(),\n",
    "                'processor': platform.processor(),\n",
    "                'cpu_cores': psutil.cpu_count(),\n",
    "                'total_memory_gb': psutil.virtual_memory().total / (1024**3),\n",
    "                'python_version': platform.python_version(),\n",
    "                'gpu_available': GPU_AVAILABLE\n",
    "            },\n",
    "            'analysis_timestamp': datetime.now().isoformat(),\n",
    "            'analysis_results': self.analysis_results,\n",
    "            'comparison_data': self.compare_model_resource_usage().to_dict('records')\n",
    "        }\n",
    "        \n",
    "        # Calculate recommendations\n",
    "        recommendations = self._generate_recommendations()\n",
    "        report['recommendations'] = recommendations\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self):\n",
    "        \"\"\"Generate resource optimization recommendations.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # Analyze CPU usage\n",
    "        cpu_usage = []\n",
    "        for results in self.analysis_results.values():\n",
    "            if isinstance(results, dict) and 'avg_cpu_percent' in results:\n",
    "                cpu_usage.append(results['avg_cpu_percent'])\n",
    "        \n",
    "        if cpu_usage:\n",
    "            avg_cpu = np.mean(cpu_usage)\n",
    "            if avg_cpu > 80:\n",
    "                recommendations.append(\"High CPU usage detected. Consider reducing batch size or using CPU optimization techniques.\")\n",
    "            elif avg_cpu < 20:\n",
    "                recommendations.append(\"Low CPU usage detected. Consider increasing batch size for better resource utilization.\")\n",
    "        \n",
    "        # Analyze memory usage\n",
    "        memory_usage = []\n",
    "        for results in self.analysis_results.values():\n",
    "            if isinstance(results, dict) and 'avg_process_memory_gb' in results:\n",
    "                memory_usage.append(results['avg_process_memory_gb'])\n",
    "        \n",
    "        if memory_usage:\n",
    "            avg_memory = np.mean(memory_usage)\n",
    "            total_memory = psutil.virtual_memory().total / (1024**3)\n",
    "            memory_ratio = avg_memory / total_memory\n",
    "            \n",
    "            if memory_ratio > 0.8:\n",
    "                recommendations.append(\"High memory usage detected. Consider reducing model size or batch size.\")\n",
    "            elif memory_ratio < 0.2:\n",
    "                recommendations.append(\"Low memory usage detected. Consider increasing model capacity or batch size.\")\n",
    "        \n",
    "        # GPU recommendations\n",
    "        if GPU_AVAILABLE:\n",
    "            recommendations.append(\"GPU available. Consider using GPU acceleration for faster training.\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Run the resource usage analysis\n",
    "print(\"Initializing Resource Usage Analyzer...\")\n",
    "analyzer = ModelResourceAnalyzer()\n",
    "\n",
    "# Analyze transformer training\n",
    "print(\"\\n1. Analyzing Transformer Training...\")\n",
    "transformer_results = analyzer.analyze_transformer_training(epochs=3, batch_size=16)\n",
    "\n",
    "# Analyze RL training\n",
    "print(\"\\n2. Analyzing RL Training...\")\n",
    "rl_results = analyzer.analyze_rl_training(episodes=500)\n",
    "\n",
    "# Analyze federated learning\n",
    "print(\"\\n3. Analyzing Federated Learning...\")\n",
    "federated_results = analyzer.analyze_federated_training(rounds=5, clients=3)\n",
    "\n",
    "# Analyze inference resource usage\n",
    "print(\"\\n4. Analyzing Inference Resource Usage...\")\n",
    "transformer_inference = analyzer.analyze_inference_resource_usage('transformer', [1, 8, 32])\n",
    "rl_inference = analyzer.analyze_inference_resource_usage('rl_agent', [1, 8, 32])\n",
    "\n",
    "# Generate comparison and visualizations\n",
    "print(\"\\n5. Generating Comparisons and Visualizations...\")\n",
    "comparison_df = analyzer.compare_model_resource_usage()\n",
    "analyzer.visualize_resource_usage()\n",
    "\n",
    "# Generate comprehensive report\n",
    "print(\"\\n6. Generating Resource Usage Report...\")\n",
    "resource_report = analyzer.generate_resource_report()\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open('resource_usage_analysis_results.json', 'w') as f:\n",
    "    json.dump(resource_report, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\nResource usage analysis completed!\")\n",
    "print(\"Results saved to 'resource_usage_analysis_results.json'\")\n",
    "print(\"Visualizations saved to 'resource_usage_analysis.png'\")\n",
    "\n",
    "# Display summary results\n",
    "print(\"\\nSUMMARY RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nCPU Usage Summary:\")\n",
    "for analysis_name, results in analyzer.analysis_results.items():\n",
    "    if isinstance(results, dict) and 'avg_cpu_percent' in results:\n",
    "        print(f\"{analysis_name}: {results['avg_cpu_percent']:.1f}%\")\n",
    "\n",
    "print(\"\\nMemory Usage Summary:\")\n",
    "for analysis_name, results in analyzer.analysis_results.items():\n",
    "    if isinstance(results, dict) and 'avg_process_memory_gb' in results:\n",
    "        print(f\"{analysis_name}: {results['avg_process_memory_gb']:.2f} GB\")\n",
    "\n",
    "print(\"\\nTraining Time Summary:\")\n",
    "for analysis_name, results in analyzer.analysis_results.items():\n",
    "    if isinstance(results, dict) and 'training_time' in results:\n",
    "        print(f\"{analysis_name}: {results['training_time']:.1f} seconds\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "for i, rec in enumerate(resource_report['recommendations'], 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    " \n",
    "print(\"\\nResource Usage Analysis Completed Successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
