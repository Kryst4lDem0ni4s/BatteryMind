{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71953ca4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BatteryMind - Degradation Pattern Analysis Notebook\n",
    "\n",
    "Advanced analysis of battery degradation patterns, capacity fade mechanisms,\n",
    "and lifecycle modeling. This notebook provides deep insights into battery\n",
    "aging processes and degradation prediction capabilities.\n",
    "\n",
    "Features:\n",
    "- Capacity fade analysis and modeling\n",
    "- Degradation mechanism identification\n",
    "- Lifecycle prediction and forecasting\n",
    "- Environmental impact on degradation\n",
    "- Comparative analysis across battery types\n",
    "- Physics-informed degradation modeling\n",
    "\n",
    "Author: BatteryMind Development Team\n",
    "Version: 1.0.0\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scientific computing and modeling\n",
    "from scipy import stats, optimize\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Time series analysis\n",
    "import datetime as dt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Advanced analytics\n",
    "from scipy.integrate import odeint\n",
    "from scipy.stats import weibull_min, norm, lognorm\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"BatteryMind - Degradation Pattern Analysis Notebook\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load degradation and related datasets\n",
    "print(\"Loading degradation analysis datasets...\")\n",
    "\n",
    "# Load datasets\n",
    "degradation_curves = pd.read_csv('../../training-data/synthetic_datasets/degradation_curves.csv')\n",
    "battery_telemetry = pd.read_csv('../../training-data/synthetic_datasets/battery_telemetry.csv')\n",
    "environmental_data = pd.read_csv('../../training-data/synthetic_datasets/environmental_data.csv')\n",
    "\n",
    "print(f\"Degradation curves shape: {degradation_curves.shape}\")\n",
    "print(f\"Battery telemetry shape: {battery_telemetry.shape}\")\n",
    "print(f\"Environmental data shape: {environmental_data.shape}\")\n",
    "\n",
    "# Data Overview\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEGRADATION DATA OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nDegradation Curves Dataset Info:\")\n",
    "print(degradation_curves.info())\n",
    "\n",
    "print(\"\\nDegradation Statistics:\")\n",
    "print(degradation_curves.describe())\n",
    "\n",
    "print(\"\\nUnique Values:\")\n",
    "for col in degradation_curves.columns:\n",
    "    if degradation_curves[col].dtype == 'object':\n",
    "        print(f\"{col}: {degradation_curves[col].nunique()} unique values\")\n",
    "\n",
    "# Capacity Fade Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CAPACITY FADE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ensure we have the required columns\n",
    "required_cols = ['cycle_count', 'capacity_retention', 'battery_id']\n",
    "available_cols = [col for col in required_cols if col in degradation_curves.columns]\n",
    "print(f\"Available columns for analysis: {available_cols}\")\n",
    "\n",
    "if 'capacity_retention' in degradation_curves.columns and 'cycle_count' in degradation_curves.columns:\n",
    "    # Overall capacity fade trends\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Individual battery degradation curves\n",
    "    plt.subplot(2, 2, 1)\n",
    "    if 'battery_id' in degradation_curves.columns:\n",
    "        sample_batteries = degradation_curves['battery_id'].unique()[:10]\n",
    "        for battery_id in sample_batteries:\n",
    "            battery_data = degradation_curves[degradation_curves['battery_id'] == battery_id]\n",
    "            plt.plot(battery_data['cycle_count'], battery_data['capacity_retention'], \n",
    "                    alpha=0.7, linewidth=1)\n",
    "    else:\n",
    "        plt.scatter(degradation_curves['cycle_count'], degradation_curves['capacity_retention'], \n",
    "                   alpha=0.5, s=1)\n",
    "    \n",
    "    plt.xlabel('Cycle Count')\n",
    "    plt.ylabel('Capacity Retention')\n",
    "    plt.title('Individual Battery Degradation Curves')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Average degradation trend\n",
    "    plt.subplot(2, 2, 2)\n",
    "    # Group by cycle count and calculate mean capacity retention\n",
    "    cycle_groups = degradation_curves.groupby('cycle_count')['capacity_retention'].agg(['mean', 'std', 'count'])\n",
    "    \n",
    "    plt.plot(cycle_groups.index, cycle_groups['mean'], 'b-', linewidth=2, label='Mean')\n",
    "    plt.fill_between(cycle_groups.index, \n",
    "                     cycle_groups['mean'] - cycle_groups['std'],\n",
    "                     cycle_groups['mean'] + cycle_groups['std'],\n",
    "                     alpha=0.3, label='Â±1 STD')\n",
    "    plt.xlabel('Cycle Count')\n",
    "    plt.ylabel('Capacity Retention')\n",
    "    plt.title('Average Degradation Trend')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Degradation rate analysis\n",
    "    plt.subplot(2, 2, 3)\n",
    "    # Calculate degradation rate (capacity loss per cycle)\n",
    "    if 'battery_id' in degradation_curves.columns:\n",
    "        degradation_rates = []\n",
    "        for battery_id in degradation_curves['battery_id'].unique():\n",
    "            battery_data = degradation_curves[degradation_curves['battery_id'] == battery_id].sort_values('cycle_count')\n",
    "            if len(battery_data) > 1:\n",
    "                # Calculate rate of capacity loss\n",
    "                capacity_diff = battery_data['capacity_retention'].diff()\n",
    "                cycle_diff = battery_data['cycle_count'].diff()\n",
    "                rate = -capacity_diff / cycle_diff  # Negative because capacity decreases\n",
    "                degradation_rates.extend(rate.dropna().values)\n",
    "        \n",
    "        plt.hist(degradation_rates, bins=50, alpha=0.7, edgecolor='black')\n",
    "        plt.xlabel('Degradation Rate (Capacity Loss per Cycle)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Degradation Rate Distribution')\n",
    "    \n",
    "    # End-of-life analysis\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Define end-of-life as 80% capacity retention\n",
    "    eol_threshold = 0.8\n",
    "    \n",
    "    if 'battery_id' in degradation_curves.columns:\n",
    "        eol_cycles = []\n",
    "        for battery_id in degradation_curves['battery_id'].unique():\n",
    "            battery_data = degradation_curves[degradation_curves['battery_id'] == battery_id]\n",
    "            eol_data = battery_data[battery_data['capacity_retention'] <= eol_threshold]\n",
    "            if len(eol_data) > 0:\n",
    "                eol_cycles.append(eol_data['cycle_count'].min())\n",
    "        \n",
    "        if eol_cycles:\n",
    "            plt.hist(eol_cycles, bins=30, alpha=0.7, edgecolor='black')\n",
    "            plt.xlabel('Cycles to End-of-Life (80% capacity)')\n",
    "            plt.ylabel('Number of Batteries')\n",
    "            plt.title('End-of-Life Distribution')\n",
    "            plt.axvline(np.mean(eol_cycles), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(eol_cycles):.0f} cycles')\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Degradation statistics\n",
    "    print(f\"Capacity Retention Statistics:\")\n",
    "    print(f\"Mean: {degradation_curves['capacity_retention'].mean():.3f}\")\n",
    "    print(f\"Min: {degradation_curves['capacity_retention'].min():.3f}\")\n",
    "    print(f\"Max: {degradation_curves['capacity_retention'].max():.3f}\")\n",
    "    print(f\"Standard Deviation: {degradation_curves['capacity_retention'].std():.3f}\")\n",
    "    \n",
    "    if 'eol_cycles' in locals() and eol_cycles:\n",
    "        print(f\"\\nEnd-of-Life Analysis (80% capacity threshold):\")\n",
    "        print(f\"Mean cycles to EOL: {np.mean(eol_cycles):.0f}\")\n",
    "        print(f\"Median cycles to EOL: {np.median(eol_cycles):.0f}\")\n",
    "        print(f\"EOL range: {np.min(eol_cycles):.0f} - {np.max(eol_cycles):.0f} cycles\")\n",
    "\n",
    "# Degradation Mechanism Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEGRADATION MECHANISM ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze different degradation mechanisms\n",
    "if 'temperature' in degradation_curves.columns or 'temperature' in battery_telemetry.columns:\n",
    "    # Temperature impact on degradation\n",
    "    \n",
    "    # Merge temperature data if needed\n",
    "    if 'temperature' not in degradation_curves.columns and 'battery_id' in degradation_curves.columns:\n",
    "        # Calculate average temperature per battery\n",
    "        temp_data = battery_telemetry.groupby('battery_id')['temperature'].mean().reset_index()\n",
    "        degradation_curves = degradation_curves.merge(temp_data, on='battery_id', how='left')\n",
    "    \n",
    "    if 'temperature' in degradation_curves.columns:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Temperature vs degradation rate\n",
    "        plt.subplot(2, 2, 1)\n",
    "        \n",
    "        # Calculate degradation rate for each battery\n",
    "        if 'battery_id' in degradation_curves.columns:\n",
    "            battery_degradation = []\n",
    "            for battery_id in degradation_curves['battery_id'].unique():\n",
    "                battery_data = degradation_curves[degradation_curves['battery_id'] == battery_id]\n",
    "                if len(battery_data) > 1:\n",
    "                    # Linear fit to get degradation rate\n",
    "                    cycles = battery_data['cycle_count'].values\n",
    "                    capacity = battery_data['capacity_retention'].values\n",
    "                    if len(cycles) > 1:\n",
    "                        slope, _, _, _, _ = stats.linregress(cycles, capacity)\n",
    "                        avg_temp = battery_data['temperature'].mean()\n",
    "                        battery_degradation.append({'temperature': avg_temp, 'degradation_rate': -slope})\n",
    "            \n",
    "            if battery_degradation:\n",
    "                deg_df = pd.DataFrame(battery_degradation)\n",
    "                plt.scatter(deg_df['temperature'], deg_df['degradation_rate'], alpha=0.7)\n",
    "                \n",
    "                # Fit exponential relationship (Arrhenius-like)\n",
    "                try:\n",
    "                    popt, _ = optimize.curve_fit(lambda x, a, b: a * np.exp(b * x), \n",
    "                                               deg_df['temperature'], deg_df['degradation_rate'])\n",
    "                    temp_range = np.linspace(deg_df['temperature'].min(), deg_df['temperature'].max(), 100)\n",
    "                    plt.plot(temp_range, popt[0] * np.exp(popt[1] * temp_range), \n",
    "                            'r-', label=f'Exponential fit: {popt[0]:.2e} * exp({popt[1]:.3f} * T)')\n",
    "                    plt.legend()\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                plt.xlabel('Average Temperature (Â°C)')\n",
    "                plt.ylabel('Degradation Rate (per cycle)')\n",
    "                plt.title('Temperature vs Degradation Rate')\n",
    "        \n",
    "        # Temperature distribution impact\n",
    "        plt.subplot(2, 2, 2)\n",
    "        temp_bins = pd.cut(degradation_curves['temperature'], bins=5)\n",
    "        degradation_by_temp = degradation_curves.groupby(temp_bins)['capacity_retention'].mean()\n",
    "        \n",
    "        temp_labels = [f\"{interval.left:.1f}-{interval.right:.1f}Â°C\" for interval in degradation_by_temp.index]\n",
    "        plt.bar(range(len(temp_labels)), degradation_by_temp.values)\n",
    "        plt.xlabel('Temperature Range')\n",
    "        plt.ylabel('Average Capacity Retention')\n",
    "        plt.title('Capacity Retention by Temperature Range')\n",
    "        plt.xticks(range(len(temp_labels)), temp_labels, rotation=45)\n",
    "        \n",
    "        # Cycle count vs temperature impact\n",
    "        plt.subplot(2, 2, 3)\n",
    "        if len(degradation_curves) > 100:\n",
    "            sample_data = degradation_curves.sample(n=1000)  # Sample for visualization\n",
    "        else:\n",
    "            sample_data = degradation_curves\n",
    "        \n",
    "        scatter = plt.scatter(sample_data['cycle_count'], sample_data['capacity_retention'], \n",
    "                            c=sample_data['temperature'], cmap='coolwarm', alpha=0.6)\n",
    "        plt.colorbar(scatter, label='Temperature (Â°C)')\n",
    "        plt.xlabel('Cycle Count')\n",
    "        plt.ylabel('Capacity Retention')\n",
    "        plt.title('Degradation vs Cycles (colored by temperature)')\n",
    "        \n",
    "        # Arrhenius plot for temperature dependence\n",
    "        plt.subplot(2, 2, 4)\n",
    "        if 'battery_degradation' in locals() and len(battery_degradation) > 0:\n",
    "            deg_df = pd.DataFrame(battery_degradation)\n",
    "            # Convert temperature to Kelvin and take reciprocal\n",
    "            temp_kelvin = deg_df['temperature'] + 273.15\n",
    "            inv_temp = 1000 / temp_kelvin  # 1000/T for better scaling\n",
    "            \n",
    "            plt.scatter(inv_temp, np.log(deg_df['degradation_rate']), alpha=0.7)\n",
    "            plt.xlabel('1000/T (Kâ»Â¹)')\n",
    "            plt.ylabel('ln(Degradation Rate)')\n",
    "            plt.title('Arrhenius Plot')\n",
    "            \n",
    "            # Linear fit for activation energy\n",
    "            try:\n",
    "                slope, intercept, r_value, _, _ = stats.linregress(inv_temp, np.log(deg_df['degradation_rate']))\n",
    "                plt.plot(inv_temp, slope * inv_temp + intercept, 'r-', \n",
    "                        label=f'RÂ² = {r_value**2:.3f}')\n",
    "                plt.legend()\n",
    "                \n",
    "                # Calculate activation energy (simplified)\n",
    "                activation_energy = -slope * 8.314  # R = 8.314 J/mol/K\n",
    "                print(f\"Estimated activation energy: {activation_energy:.1f} J/mol\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Degradation Modeling and Prediction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEGRADATION MODELING AND PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'capacity_retention' in degradation_curves.columns and 'cycle_count' in degradation_curves.columns:\n",
    "    \n",
    "    # Prepare data for modeling\n",
    "    modeling_data = degradation_curves[['cycle_count', 'capacity_retention']].dropna()\n",
    "    \n",
    "    if len(modeling_data) > 100:\n",
    "        # Sample for faster computation\n",
    "        modeling_data = modeling_data.sample(n=5000, random_state=42)\n",
    "    \n",
    "    X = modeling_data[['cycle_count']]\n",
    "    y = modeling_data['capacity_retention']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Model 1: Linear degradation model\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    y_pred_linear = linear_model.predict(X_test)\n",
    "    \n",
    "    # Model 2: Polynomial degradation model\n",
    "    poly_features = PolynomialFeatures(degree=2)\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    X_test_poly = poly_features.transform(X_test)\n",
    "    \n",
    "    poly_model = Ridge(alpha=1.0)\n",
    "    poly_model.fit(X_train_poly, y_train)\n",
    "    y_pred_poly = poly_model.predict(X_test_poly)\n",
    "    \n",
    "    # Model 3: Exponential decay model\n",
    "    def exponential_decay(x, a, b, c):\n",
    "        return a * np.exp(-b * x) + c\n",
    "    \n",
    "    try:\n",
    "        popt_exp, _ = optimize.curve_fit(exponential_decay, X_train.values.flatten(), y_train.values)\n",
    "        y_pred_exp = exponential_decay(X_test.values.flatten(), *popt_exp)\n",
    "    except:\n",
    "        y_pred_exp = y_pred_linear  # Fallback\n",
    "        popt_exp = [1, 0, 0]\n",
    "    \n",
    "    # Model 4: Power law model\n",
    "    def power_law(x, a, b, c):\n",
    "        return a * np.power(x + 1, -b) + c\n",
    "    \n",
    "    try:\n",
    "        popt_power, _ = optimize.curve_fit(power_law, X_train.values.flatten(), y_train.values)\n",
    "        y_pred_power = power_law(X_test.values.flatten(), *popt_power)\n",
    "    except:\n",
    "        y_pred_power = y_pred_linear  # Fallback\n",
    "        popt_power = [1, 0, 0]\n",
    "    \n",
    "    # Evaluate models\n",
    "    models = {\n",
    "        'Linear': y_pred_linear,\n",
    "        'Polynomial': y_pred_poly,\n",
    "        'Exponential': y_pred_exp,\n",
    "        'Power Law': y_pred_power\n",
    "    }\n",
    "    \n",
    "    print(\"Model Performance Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    model_scores = {}\n",
    "    for name, predictions in models.items():\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        model_scores[name] = {'MSE': mse, 'RÂ²': r2}\n",
    "        print(f\"{name:12} | MSE: {mse:.6f} | RÂ²: {r2:.4f}\")\n",
    "    \n",
    "    # Visualization of model predictions\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Model comparison\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(y_test, y_pred_linear, alpha=0.5, label='Linear')\n",
    "    plt.scatter(y_test, y_pred_poly, alpha=0.5, label='Polynomial')\n",
    "    plt.scatter(y_test, y_pred_exp, alpha=0.5, label='Exponential')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', alpha=0.8)\n",
    "    plt.xlabel('Actual Capacity Retention')\n",
    "    plt.ylabel('Predicted Capacity Retention')\n",
    "    plt.title('Model Predictions vs Actual')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Residual analysis\n",
    "    plt.subplot(2, 2, 2)\n",
    "    residuals_linear = y_test - y_pred_linear\n",
    "    residuals_poly = y_test - y_pred_poly\n",
    "    \n",
    "    plt.scatter(y_pred_linear, residuals_linear, alpha=0.5, label='Linear')\n",
    "    plt.scatter(y_pred_poly, residuals_poly, alpha=0.5, label='Polynomial')\n",
    "    plt.axhline(y=0, color='k', linestyle='--', alpha=0.8)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Analysis')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Degradation curves with model fits\n",
    "    plt.subplot(2, 2, 3)\n",
    "    cycle_range = np.linspace(X.min().values[0], X.max().values[0], 200)\n",
    "    \n",
    "    # Plot sample of actual data\n",
    "    sample_indices = np.random.choice(len(modeling_data), size=min(1000, len(modeling_data)), replace=False)\n",
    "    sample_data = modeling_data.iloc[sample_indices]\n",
    "    plt.scatter(sample_data['cycle_count'], sample_data['capacity_retention'], \n",
    "               alpha=0.3, s=1, color='gray', label='Data')\n",
    "    \n",
    "    # Plot model predictions\n",
    "    plt.plot(cycle_range, linear_model.predict(cycle_range.reshape(-1, 1)), \n",
    "             'r-', label='Linear', linewidth=2)\n",
    "    \n",
    "    cycle_range_poly = poly_features.transform(cycle_range.reshape(-1, 1))\n",
    "    plt.plot(cycle_range, poly_model.predict(cycle_range_poly), \n",
    "             'g-', label='Polynomial', linewidth=2)\n",
    "    \n",
    "    plt.plot(cycle_range, exponential_decay(cycle_range, *popt_exp), \n",
    "             'b-', label='Exponential', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Cycle Count')\n",
    "    plt.ylabel('Capacity Retention')\n",
    "    plt.title('Degradation Model Comparison')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Feature importance (using Random Forest)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # Add more features if available\n",
    "    feature_columns = ['cycle_count']\n",
    "    if 'temperature' in degradation_curves.columns:\n",
    "        feature_columns.append('temperature')\n",
    "    if 'state_of_charge' in degradation_curves.columns:\n",
    "        feature_columns.append('state_of_charge')\n",
    "    \n",
    "    if len(feature_columns) > 1:\n",
    "        rf_data = degradation_curves[feature_columns + ['capacity_retention']].dropna()\n",
    "        if len(rf_data) > 100:\n",
    "            rf_data = rf_data.sample(n=2000, random_state=42)\n",
    "        \n",
    "        X_rf = rf_data[feature_columns]\n",
    "        y_rf = rf_data['capacity_retention']\n",
    "        \n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_rf, y_rf)\n",
    "        \n",
    "        feature_importance = rf_model.feature_importances_\n",
    "        plt.bar(feature_columns, feature_importance)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.title('Feature Importance (Random Forest)')\n",
    "        plt.xticks(rotation=45)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Insufficient features\\nfor importance analysis', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Feature Importance Analysis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Lifecycle Prediction and Forecasting\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LIFECYCLE PREDICTION AND FORECASTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'battery_id' in degradation_curves.columns:\n",
    "    # Select a representative battery for detailed analysis\n",
    "    battery_ids = degradation_curves['battery_id'].unique()\n",
    "    sample_battery = battery_ids[0]\n",
    "    \n",
    "    battery_data = degradation_curves[degradation_curves['battery_id'] == sample_battery].sort_values('cycle_count')\n",
    "    \n",
    "    if len(battery_data) > 10:\n",
    "        print(f\"Analyzing battery {sample_battery} with {len(battery_data)} data points\")\n",
    "        \n",
    "        # Prepare time series data\n",
    "        ts_data = battery_data.set_index('cycle_count')['capacity_retention']\n",
    "        \n",
    "        # Split into train/test\n",
    "        split_point = int(len(ts_data) * 0.8)\n",
    "        train_data = ts_data[:split_point]\n",
    "        test_data = ts_data[split_point:]\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Original time series\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(train_data.index, train_data.values, 'b-', label='Training Data', linewidth=2)\n",
    "        plt.plot(test_data.index, test_data.values, 'g-', label='Test Data', linewidth=2)\n",
    "        plt.xlabel('Cycle Count')\n",
    "        plt.ylabel('Capacity Retention')\n",
    "        plt.title('Battery Degradation Time Series')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Exponential smoothing forecast\n",
    "        plt.subplot(2, 2, 2)\n",
    "        try:\n",
    "            exp_smooth_model = ExponentialSmoothing(train_data, trend='add', seasonal=None)\n",
    "            exp_smooth_fit = exp_smooth_model.fit()\n",
    "            \n",
    "            # Forecast\n",
    "            forecast_steps = len(test_data)\n",
    "            forecast = exp_smooth_fit.forecast(steps=forecast_steps)\n",
    "            \n",
    "            plt.plot(train_data.index, train_data.values, 'b-', label='Training', linewidth=2)\n",
    "            plt.plot(test_data.index, test_data.values, 'g-', label='Actual', linewidth=2)\n",
    "            plt.plot(test_data.index, forecast, 'r--', label='Forecast', linewidth=2)\n",
    "            \n",
    "            # Calculate forecast accuracy\n",
    "            forecast_mse = mean_squared_error(test_data.values, forecast)\n",
    "            plt.title(f'Exponential Smoothing Forecast (MSE: {forecast_mse:.4f})')\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Exponential smoothing failed:\\n{str(e)[:50]}...', \n",
    "                    ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Exponential Smoothing Forecast')\n",
    "        \n",
    "        plt.xlabel('Cycle Count')\n",
    "        plt.ylabel('Capacity Retention')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Physics-based degradation model\n",
    "        plt.subplot(2, 2, 3)\n",
    "        \n",
    "        # Implement simplified physics-based model\n",
    "        def physics_degradation_model(cycles, params):\n",
    "            \"\"\"\n",
    "            Simplified physics-based degradation model\n",
    "            params: [initial_capacity, linear_fade_rate, sqrt_fade_rate]\n",
    "            \"\"\"\n",
    "            initial_cap, linear_rate, sqrt_rate = params\n",
    "            return initial_cap - linear_rate * cycles - sqrt_rate * np.sqrt(cycles)\n",
    "        \n",
    "        # Fit physics model\n",
    "        try:\n",
    "            cycles_train = train_data.index.values\n",
    "            capacity_train = train_data.values\n",
    "            \n",
    "            # Initial parameter guess\n",
    "            initial_guess = [1.0, 1e-5, 1e-3]\n",
    "            \n",
    "            popt_physics, _ = optimize.curve_fit(physics_degradation_model, \n",
    "                                               cycles_train, capacity_train, \n",
    "                                               p0=initial_guess)\n",
    "            \n",
    "            # Predict on test data\n",
    "            cycles_test = test_data.index.values\n",
    "            physics_forecast = physics_degradation_model(cycles_test, popt_physics)\n",
    "            \n",
    "            plt.plot(train_data.index, train_data.values, 'b-', label='Training', linewidth=2)\n",
    "            plt.plot(test_data.index, test_data.values, 'g-', label='Actual', linewidth=2)\n",
    "            plt.plot(test_data.index, physics_forecast, 'r--', label='Physics Model', linewidth=2)\n",
    "            \n",
    "            physics_mse = mean_squared_error(test_data.values, physics_forecast)\n",
    "            plt.title(f'Physics-Based Model (MSE: {physics_mse:.4f})')\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Physics model failed:\\n{str(e)[:50]}...', \n",
    "                    ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Physics-Based Model')\n",
    "        \n",
    "        plt.xlabel('Cycle Count')\n",
    "        plt.ylabel('Capacity Retention')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # End-of-life prediction\n",
    "        plt.subplot(2, 2, 4)\n",
    "        \n",
    "        # Extrapolate to predict end-of-life (80% capacity)\n",
    "        eol_threshold = 0.8\n",
    "        max_cycles = 5000  # Maximum cycles to predict\n",
    "        \n",
    "        extended_cycles = np.arange(0, max_cycles, 10)\n",
    "        \n",
    "        # Use best performing model for EOL prediction\n",
    "        if 'popt_physics' in locals():\n",
    "            extended_prediction = physics_degradation_model(extended_cycles, popt_physics)\n",
    "            model_name = \"Physics-Based\"\n",
    "        else:\n",
    "            # Fallback to linear extrapolation\n",
    "            slope, intercept, _, _, _ = stats.linregress(train_data.index, train_data.values)\n",
    "            extended_prediction = slope * extended_cycles + intercept\n",
    "            model_name = \"Linear\"\n",
    "        \n",
    "        plt.plot(extended_cycles, extended_prediction, 'b-', label=f'{model_name} Prediction', linewidth=2)\n",
    "        plt.axhline(y=eol_threshold, color='r', linestyle='--', alpha=0.8, label='EOL Threshold (80%)')\n",
    "        \n",
    "        # Find EOL point\n",
    "        eol_indices = np.where(extended_prediction <= eol_threshold)[0]\n",
    "        if len(eol_indices) > 0:\n",
    "            eol_cycle = extended_cycles[eol_indices[0]]\n",
    "            plt.axvline(x=eol_cycle, color='r', linestyle=':', alpha=0.8, \n",
    "                       label=f'Predicted EOL: {eol_cycle:.0f} cycles')\n",
    "            print(f\"Predicted End-of-Life for battery {sample_battery}: {eol_cycle:.0f} cycles\")\n",
    "        \n",
    "        plt.xlabel('Cycle Count')\n",
    "        plt.ylabel('Capacity Retention')\n",
    "        plt.title('End-of-Life Prediction')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Comparative Degradation Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARATIVE DEGRADATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze degradation patterns across different conditions\n",
    "if 'battery_id' in degradation_curves.columns and len(degradation_curves['battery_id'].unique()) > 5:\n",
    "    \n",
    "    # Group batteries by degradation characteristics\n",
    "    battery_summary = []\n",
    "    \n",
    "    for battery_id in degradation_curves['battery_id'].unique()[:20]:  # Limit for performance\n",
    "        battery_data = degradation_curves[degradation_curves['battery_id'] == battery_id]\n",
    "        \n",
    "        if len(battery_data) > 5:\n",
    "            # Calculate degradation metrics\n",
    "            initial_capacity = battery_data['capacity_retention'].max()\n",
    "            final_capacity = battery_data['capacity_retention'].min()\n",
    "            total_cycles = battery_data['cycle_count'].max() - battery_data['cycle_count'].min()\n",
    "            \n",
    "            if total_cycles > 0:\n",
    "                avg_degradation_rate = (initial_capacity - final_capacity) / total_cycles\n",
    "                \n",
    "                # Additional metrics\n",
    "                avg_temp = battery_data['temperature'].mean() if 'temperature' in battery_data.columns else 25.0\n",
    "                \n",
    "                battery_summary.append({\n",
    "                    'battery_id': battery_id,\n",
    "                    'initial_capacity': initial_capacity,\n",
    "                    'final_capacity': final_capacity,\n",
    "                    'total_cycles': total_cycles,\n",
    "                    'degradation_rate': avg_degradation_rate,\n",
    "                    'avg_temperature': avg_temp\n",
    "                })\n",
    "    \n",
    "    # Continuation from the previous code block...\n",
    "\n",
    "if battery_summary:\n",
    "    summary_df = pd.DataFrame(battery_summary)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Degradation rate distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(summary_df['degradation_rate'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Degradation Rate (per cycle)')\n",
    "    plt.ylabel('Number of Batteries')\n",
    "    plt.title('Degradation Rate Distribution')\n",
    "    plt.axvline(summary_df['degradation_rate'].mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {summary_df[\"degradation_rate\"].mean():.2e}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Temperature vs degradation rate\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(summary_df['avg_temperature'], summary_df['degradation_rate'], alpha=0.7)\n",
    "    plt.xlabel('Average Temperature (Â°C)')\n",
    "    plt.ylabel('Degradation Rate (per cycle)')\n",
    "    plt.title('Temperature vs Degradation Rate')\n",
    "    \n",
    "    # Correlation analysis\n",
    "    if len(summary_df) > 3:\n",
    "        corr_coef = summary_df['avg_temperature'].corr(summary_df['degradation_rate'])\n",
    "        plt.text(0.05, 0.95, f'Correlation: {corr_coef:.3f}', \n",
    "                transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    \n",
    "    # Cycle life distribution\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(summary_df['total_cycles'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Total Cycles Observed')\n",
    "    plt.ylabel('Number of Batteries')\n",
    "    plt.title('Cycle Life Distribution')\n",
    "    \n",
    "    # Capacity retention vs cycles\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(summary_df['total_cycles'], summary_df['final_capacity'], alpha=0.7)\n",
    "    plt.xlabel('Total Cycles')\n",
    "    plt.ylabel('Final Capacity Retention')\n",
    "    plt.title('Capacity Retention vs Cycle Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical summary\n",
    "    print(\"Battery Degradation Summary Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Number of batteries analyzed: {len(summary_df)}\")\n",
    "    print(f\"Average degradation rate: {summary_df['degradation_rate'].mean():.2e} per cycle\")\n",
    "    print(f\"Degradation rate std dev: {summary_df['degradation_rate'].std():.2e}\")\n",
    "    print(f\"Average cycles observed: {summary_df['total_cycles'].mean():.0f}\")\n",
    "    print(f\"Average final capacity: {summary_df['final_capacity'].mean():.3f}\")\n",
    "    \n",
    "    # Identify best and worst performing batteries\n",
    "    best_battery = summary_df.loc[summary_df['degradation_rate'].idxmin()]\n",
    "    worst_battery = summary_df.loc[summary_df['degradation_rate'].idxmax()]\n",
    "    \n",
    "    print(f\"\\nBest performing battery: {best_battery['battery_id']}\")\n",
    "    print(f\"  Degradation rate: {best_battery['degradation_rate']:.2e} per cycle\")\n",
    "    print(f\"  Average temperature: {best_battery['avg_temperature']:.1f}Â°C\")\n",
    "    \n",
    "    print(f\"\\nWorst performing battery: {worst_battery['battery_id']}\")\n",
    "    print(f\"  Degradation rate: {worst_battery['degradation_rate']:.2e} per cycle\")\n",
    "    print(f\"  Average temperature: {worst_battery['avg_temperature']:.1f}Â°C\")\n",
    "    \n",
    "    # Advanced degradation pattern analysis\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ADVANCED DEGRADATION PATTERN ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Clustering analysis for degradation patterns\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Prepare features for clustering\n",
    "    clustering_features = ['degradation_rate', 'avg_temperature', 'total_cycles', \n",
    "                          'final_capacity', 'avg_voltage', 'avg_current']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    available_features = [col for col in clustering_features if col in summary_df.columns]\n",
    "    \n",
    "    if len(available_features) >= 3:\n",
    "        X_cluster = summary_df[available_features].fillna(summary_df[available_features].mean())\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_cluster)\n",
    "        \n",
    "        # Determine optimal number of clusters using elbow method\n",
    "        inertias = []\n",
    "        k_range = range(2, min(8, len(summary_df)))\n",
    "        \n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            kmeans.fit(X_scaled)\n",
    "            inertias.append(kmeans.inertia_)\n",
    "        \n",
    "        # Find optimal k using elbow method\n",
    "        if len(inertias) > 1:\n",
    "            # Calculate rate of change\n",
    "            rate_of_change = np.diff(inertias)\n",
    "            optimal_k = k_range[np.argmin(rate_of_change)] if len(rate_of_change) > 0 else 3\n",
    "        else:\n",
    "            optimal_k = 2\n",
    "        \n",
    "        # Perform clustering\n",
    "        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "        summary_df['cluster'] = cluster_labels\n",
    "        \n",
    "        # Visualize clustering results\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        \n",
    "        # PCA for visualization\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', alpha=0.7)\n",
    "        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "        plt.title('Battery Degradation Clusters (PCA)')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        \n",
    "        # Cluster characteristics\n",
    "        plt.subplot(2, 3, 2)\n",
    "        cluster_means = summary_df.groupby('cluster')['degradation_rate'].mean()\n",
    "        plt.bar(range(len(cluster_means)), cluster_means.values, alpha=0.7)\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Mean Degradation Rate')\n",
    "        plt.title('Degradation Rate by Cluster')\n",
    "        plt.xticks(range(len(cluster_means)), [f'Cluster {i}' for i in cluster_means.index])\n",
    "        \n",
    "        # Temperature distribution by cluster\n",
    "        plt.subplot(2, 3, 3)\n",
    "        for cluster_id in sorted(summary_df['cluster'].unique()):\n",
    "            cluster_data = summary_df[summary_df['cluster'] == cluster_id]\n",
    "            plt.hist(cluster_data['avg_temperature'], alpha=0.5, \n",
    "                    label=f'Cluster {cluster_id}', bins=10)\n",
    "        plt.xlabel('Average Temperature (Â°C)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Temperature Distribution by Cluster')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Capacity retention by cluster\n",
    "        plt.subplot(2, 3, 4)\n",
    "        cluster_capacity_means = summary_df.groupby('cluster')['final_capacity'].mean()\n",
    "        plt.bar(range(len(cluster_capacity_means)), cluster_capacity_means.values, alpha=0.7)\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Mean Final Capacity')\n",
    "        plt.title('Capacity Retention by Cluster')\n",
    "        plt.xticks(range(len(cluster_capacity_means)), [f'Cluster {i}' for i in cluster_capacity_means.index])\n",
    "        \n",
    "        # Cycle life by cluster\n",
    "        plt.subplot(2, 3, 5)\n",
    "        cluster_cycle_means = summary_df.groupby('cluster')['total_cycles'].mean()\n",
    "        plt.bar(range(len(cluster_cycle_means)), cluster_cycle_means.values, alpha=0.7)\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Mean Total Cycles')\n",
    "        plt.title('Cycle Life by Cluster')\n",
    "        plt.xticks(range(len(cluster_cycle_means)), [f'Cluster {i}' for i in cluster_cycle_means.index])\n",
    "        \n",
    "        # Feature importance (PCA components)\n",
    "        plt.subplot(2, 3, 6)\n",
    "        feature_importance = np.abs(pca.components_[0])\n",
    "        plt.bar(range(len(available_features)), feature_importance, alpha=0.7)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('PCA Component 1 Weight')\n",
    "        plt.title('Feature Importance (PC1)')\n",
    "        plt.xticks(range(len(available_features)), available_features, rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print cluster analysis\n",
    "        print(f\"\\nClustering Analysis Results:\")\n",
    "        print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "        print(f\"Features used: {', '.join(available_features)}\")\n",
    "        print(f\"PCA explained variance: PC1={pca.explained_variance_ratio_[0]:.2%}, PC2={pca.explained_variance_ratio_[1]:.2%}\")\n",
    "        \n",
    "        for cluster_id in sorted(summary_df['cluster'].unique()):\n",
    "            cluster_data = summary_df[summary_df['cluster'] == cluster_id]\n",
    "            print(f\"\\nCluster {cluster_id} ({len(cluster_data)} batteries):\")\n",
    "            print(f\"  Mean degradation rate: {cluster_data['degradation_rate'].mean():.2e}\")\n",
    "            print(f\"  Mean temperature: {cluster_data['avg_temperature'].mean():.1f}Â°C\")\n",
    "            print(f\"  Mean final capacity: {cluster_data['final_capacity'].mean():.3f}\")\n",
    "            print(f\"  Mean cycles: {cluster_data['total_cycles'].mean():.0f}\")\n",
    "    \n",
    "    # Time series analysis for degradation patterns\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TIME SERIES DEGRADATION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Analyze degradation trends over time\n",
    "    if 'timestamp' in battery_data.columns:\n",
    "        # Convert timestamp to datetime if it's not already\n",
    "        battery_data['timestamp'] = pd.to_datetime(battery_data['timestamp'])\n",
    "        \n",
    "        # Group by time periods to analyze degradation trends\n",
    "        battery_data['month'] = battery_data['timestamp'].dt.to_period('M')\n",
    "        monthly_degradation = battery_data.groupby(['battery_id', 'month']).agg({\n",
    "            'capacity': 'mean',\n",
    "            'temperature': 'mean',\n",
    "            'voltage': 'mean',\n",
    "            'current': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Calculate monthly degradation rates\n",
    "        degradation_trends = []\n",
    "        for battery_id in monthly_degradation['battery_id'].unique():\n",
    "            battery_monthly = monthly_degradation[monthly_degradation['battery_id'] == battery_id].sort_values('month')\n",
    "            if len(battery_monthly) > 1:\n",
    "                capacity_trend = np.polyfit(range(len(battery_monthly)), battery_monthly['capacity'], 1)[0]\n",
    "                degradation_trends.append({\n",
    "                    'battery_id': battery_id,\n",
    "                    'monthly_degradation_rate': -capacity_trend,  # Negative slope means degradation\n",
    "                    'months_observed': len(battery_monthly)\n",
    "                })\n",
    "        \n",
    "        if degradation_trends:\n",
    "            trends_df = pd.DataFrame(degradation_trends)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
