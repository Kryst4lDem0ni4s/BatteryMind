{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279290c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BatteryMind - Reinforcement Learning Hyperparameter Tuning\n",
    "\n",
    "Advanced hyperparameter optimization for battery charging optimization RL agents.\n",
    "This notebook implements comprehensive hyperparameter tuning for PPO, DDPG, SAC, and DQN \n",
    "algorithms using Optuna for automated optimization.\n",
    "\n",
    "Features:\n",
    "- Multi-algorithm hyperparameter optimization\n",
    "- Bayesian optimization with Optuna\n",
    "- Parallel optimization across multiple trials\n",
    "- Performance tracking and visualization\n",
    "- Automated model selection based on performance metrics\n",
    "- Physics-informed constraint validation\n",
    "\n",
    "Author: BatteryMind Development Team\n",
    "Version: 1.0.0\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import logging\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# BatteryMind imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from reinforcement_learning.agents.charging_agent import ChargingAgent\n",
    "from reinforcement_learning.agents.thermal_agent import ThermalAgent\n",
    "from reinforcement_learning.environments.battery_env import BatteryEnvironment\n",
    "from reinforcement_learning.environments.charging_env import ChargingEnvironment\n",
    "from reinforcement_learning.algorithms.ppo import PPOAlgorithm\n",
    "from reinforcement_learning.algorithms.ddpg import DDPGAlgorithm\n",
    "from reinforcement_learning.algorithms.sac import SACAlgorithm\n",
    "from reinforcement_learning.algorithms.dqn import DQNAlgorithm\n",
    "from reinforcement_learning.training.rl_trainer import RLTrainer\n",
    "from training_data.generators.synthetic_generator import SyntheticDataGenerator\n",
    "from training_data.generators.physics_simulator import BatteryPhysicsSimulator\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üîã BatteryMind RL Hyperparameter Tuning Notebook\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Notebook initialized at: {datetime.now()}\")\n",
    "print()\n",
    "\n",
    "# Configuration\n",
    "OPTIMIZATION_CONFIG = {\n",
    "    'n_trials': 100,\n",
    "    'n_jobs': mp.cpu_count(),\n",
    "    'study_name': 'batterymind_rl_optimization',\n",
    "    'optimization_direction': 'maximize',\n",
    "    'pruner': 'MedianPruner',\n",
    "    'sampler': 'TPESampler',\n",
    "    'algorithms': ['PPO', 'DDPG', 'SAC', 'DQN'],\n",
    "    'environments': ['BatteryEnvironment', 'ChargingEnvironment'],\n",
    "    'evaluation_episodes': 10,\n",
    "    'max_training_steps': 50000,\n",
    "    'early_stopping_patience': 10\n",
    "}\n",
    "\n",
    "# Hyperparameter search spaces for each algorithm\n",
    "HYPERPARAMETER_SPACES = {\n",
    "    'PPO': {\n",
    "        'learning_rate': (1e-5, 1e-2),\n",
    "        'batch_size': [32, 64, 128, 256],\n",
    "        'n_epochs': [3, 5, 10, 20],\n",
    "        'gamma': (0.9, 0.999),\n",
    "        'gae_lambda': (0.9, 0.99),\n",
    "        'clip_range': (0.1, 0.4),\n",
    "        'entropy_coef': (0.0, 0.1),\n",
    "        'vf_coef': (0.1, 1.0),\n",
    "        'max_grad_norm': (0.3, 2.0),\n",
    "        'n_steps': [1024, 2048, 4096],\n",
    "        'target_kl': (0.01, 0.1)\n",
    "    },\n",
    "    'DDPG': {\n",
    "        'learning_rate': (1e-5, 1e-2),\n",
    "        'batch_size': [64, 128, 256, 512],\n",
    "        'gamma': (0.9, 0.999),\n",
    "        'tau': (0.001, 0.1),\n",
    "        'buffer_size': [100000, 500000, 1000000],\n",
    "        'exploration_noise': (0.1, 0.5),\n",
    "        'policy_noise': (0.1, 0.5),\n",
    "        'noise_clip': (0.1, 1.0),\n",
    "        'policy_freq': [1, 2, 4],\n",
    "        'learning_starts': [1000, 5000, 10000]\n",
    "    },\n",
    "    'SAC': {\n",
    "        'learning_rate': (1e-5, 1e-2),\n",
    "        'batch_size': [64, 128, 256, 512],\n",
    "        'gamma': (0.9, 0.999),\n",
    "        'tau': (0.001, 0.1),\n",
    "        'buffer_size': [100000, 500000, 1000000],\n",
    "        'target_update_interval': [1, 2, 4],\n",
    "        'target_entropy': 'auto',\n",
    "        'ent_coef': 'auto',\n",
    "        'learning_starts': [1000, 5000, 10000],\n",
    "        'train_freq': [1, 4, 8]\n",
    "    },\n",
    "    'DQN': {\n",
    "        'learning_rate': (1e-5, 1e-2),\n",
    "        'batch_size': [32, 64, 128, 256],\n",
    "        'gamma': (0.9, 0.999),\n",
    "        'buffer_size': [50000, 100000, 500000],\n",
    "        'learning_starts': [1000, 5000, 10000],\n",
    "        'target_update_interval': [1000, 5000, 10000],\n",
    "        'train_freq': [1, 4, 8],\n",
    "        'gradient_steps': [1, 2, 4],\n",
    "        'exploration_fraction': (0.1, 0.5),\n",
    "        'exploration_initial_eps': (0.5, 1.0),\n",
    "        'exploration_final_eps': (0.01, 0.2)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Network architecture search spaces\n",
    "NETWORK_ARCHITECTURES = {\n",
    "    'hidden_layers': [2, 3, 4],\n",
    "    'hidden_units': [64, 128, 256, 512],\n",
    "    'activation': ['relu', 'tanh', 'elu'],\n",
    "    'layer_norm': [True, False],\n",
    "    'dropout': (0.0, 0.5)\n",
    "}\n",
    "\n",
    "class RLHyperparameterOptimizer:\n",
    "    \"\"\"\n",
    "    Advanced hyperparameter optimizer for RL algorithms in battery management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.study = None\n",
    "        self.best_params = {}\n",
    "        self.optimization_history = []\n",
    "        self.performance_metrics = {}\n",
    "        \n",
    "        # Initialize environment and data generators\n",
    "        self.env_generators = {\n",
    "            'BatteryEnvironment': lambda: BatteryEnvironment(),\n",
    "            'ChargingEnvironment': lambda: ChargingEnvironment()\n",
    "        }\n",
    "        \n",
    "        # Initialize physics simulator for realistic evaluation\n",
    "        self.physics_sim = BatteryPhysicsSimulator()\n",
    "        \n",
    "        # Results storage\n",
    "        self.results = {\n",
    "            'trials': [],\n",
    "            'best_params_per_algorithm': {},\n",
    "            'performance_comparison': {},\n",
    "            'optimization_plots': {}\n",
    "        }\n",
    "    \n",
    "    def suggest_hyperparameters(self, trial: optuna.Trial, algorithm: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Suggest hyperparameters for a given algorithm using Optuna.\n",
    "        \n",
    "        Args:\n",
    "            trial: Optuna trial object\n",
    "            algorithm: RL algorithm name\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of suggested hyperparameters\n",
    "        \"\"\"\n",
    "        space = HYPERPARAMETER_SPACES[algorithm]\n",
    "        params = {}\n",
    "        \n",
    "        for param_name, param_range in space.items():\n",
    "            if isinstance(param_range, tuple):\n",
    "                if isinstance(param_range[0], float):\n",
    "                    params[param_name] = trial.suggest_float(param_name, *param_range)\n",
    "                else:\n",
    "                    params[param_name] = trial.suggest_int(param_name, *param_range)\n",
    "            elif isinstance(param_range, list):\n",
    "                params[param_name] = trial.suggest_categorical(param_name, param_range)\n",
    "            elif param_range == 'auto':\n",
    "                params[param_name] = 'auto'\n",
    "        \n",
    "        # Suggest network architecture\n",
    "        params['network_arch'] = {\n",
    "            'hidden_layers': trial.suggest_categorical('hidden_layers', NETWORK_ARCHITECTURES['hidden_layers']),\n",
    "            'hidden_units': trial.suggest_categorical('hidden_units', NETWORK_ARCHITECTURES['hidden_units']),\n",
    "            'activation': trial.suggest_categorical('activation', NETWORK_ARCHITECTURES['activation']),\n",
    "            'layer_norm': trial.suggest_categorical('layer_norm', NETWORK_ARCHITECTURES['layer_norm']),\n",
    "            'dropout': trial.suggest_float('dropout', *NETWORK_ARCHITECTURES['dropout'])\n",
    "        }\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def create_algorithm(self, algorithm_name: str, params: Dict[str, Any], env: Any) -> Any:\n",
    "        \"\"\"\n",
    "        Create RL algorithm instance with given hyperparameters.\n",
    "        \n",
    "        Args:\n",
    "            algorithm_name: Name of the algorithm\n",
    "            params: Hyperparameters\n",
    "            env: Environment instance\n",
    "            \n",
    "        Returns:\n",
    "            Algorithm instance\n",
    "        \"\"\"\n",
    "        if algorithm_name == 'PPO':\n",
    "            return PPOAlgorithm(\n",
    "                env=env,\n",
    "                learning_rate=params['learning_rate'],\n",
    "                batch_size=params['batch_size'],\n",
    "                n_epochs=params['n_epochs'],\n",
    "                gamma=params['gamma'],\n",
    "                gae_lambda=params['gae_lambda'],\n",
    "                clip_range=params['clip_range'],\n",
    "                entropy_coef=params['entropy_coef'],\n",
    "                vf_coef=params['vf_coef'],\n",
    "                max_grad_norm=params['max_grad_norm'],\n",
    "                n_steps=params['n_steps'],\n",
    "                target_kl=params['target_kl'],\n",
    "                network_arch=params['network_arch']\n",
    "            )\n",
    "        elif algorithm_name == 'DDPG':\n",
    "            return DDPGAlgorithm(\n",
    "                env=env,\n",
    "                learning_rate=params['learning_rate'],\n",
    "                batch_size=params['batch_size'],\n",
    "                gamma=params['gamma'],\n",
    "                tau=params['tau'],\n",
    "                buffer_size=params['buffer_size'],\n",
    "                exploration_noise=params['exploration_noise'],\n",
    "                policy_noise=params['policy_noise'],\n",
    "                noise_clip=params['noise_clip'],\n",
    "                policy_freq=params['policy_freq'],\n",
    "                learning_starts=params['learning_starts'],\n",
    "                network_arch=params['network_arch']\n",
    "            )\n",
    "        elif algorithm_name == 'SAC':\n",
    "            return SACAlgorithm(\n",
    "                env=env,\n",
    "                learning_rate=params['learning_rate'],\n",
    "                batch_size=params['batch_size'],\n",
    "                gamma=params['gamma'],\n",
    "                tau=params['tau'],\n",
    "                buffer_size=params['buffer_size'],\n",
    "                target_update_interval=params['target_update_interval'],\n",
    "                target_entropy=params['target_entropy'],\n",
    "                ent_coef=params['ent_coef'],\n",
    "                learning_starts=params['learning_starts'],\n",
    "                train_freq=params['train_freq'],\n",
    "                network_arch=params['network_arch']\n",
    "            )\n",
    "        elif algorithm_name == 'DQN':\n",
    "            return DQNAlgorithm(\n",
    "                env=env,\n",
    "                learning_rate=params['learning_rate'],\n",
    "                batch_size=params['batch_size'],\n",
    "                gamma=params['gamma'],\n",
    "                buffer_size=params['buffer_size'],\n",
    "                learning_starts=params['learning_starts'],\n",
    "                target_update_interval=params['target_update_interval'],\n",
    "                train_freq=params['train_freq'],\n",
    "                gradient_steps=params['gradient_steps'],\n",
    "                exploration_fraction=params['exploration_fraction'],\n",
    "                exploration_initial_eps=params['exploration_initial_eps'],\n",
    "                exploration_final_eps=params['exploration_final_eps'],\n",
    "                network_arch=params['network_arch']\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown algorithm: {algorithm_name}\")\n",
    "    \n",
    "    def evaluate_agent(self, agent: Any, env: Any, n_episodes: int = 10) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate RL agent performance.\n",
    "        \n",
    "        Args:\n",
    "            agent: Trained RL agent\n",
    "            env: Environment\n",
    "            n_episodes: Number of evaluation episodes\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of performance metrics\n",
    "        \"\"\"\n",
    "        episode_rewards = []\n",
    "        episode_lengths = []\n",
    "        battery_health_improvements = []\n",
    "        energy_efficiency_scores = []\n",
    "        safety_violations = []\n",
    "        \n",
    "        for episode in range(n_episodes):\n",
    "            obs = env.reset()\n",
    "            total_reward = 0\n",
    "            episode_length = 0\n",
    "            initial_soh = obs.get('soh', 1.0)\n",
    "            safety_violation_count = 0\n",
    "            \n",
    "            while True:\n",
    "                action = agent.predict(obs)\n",
    "                obs, reward, done, info = env.step(action)\n",
    "                \n",
    "                total_reward += reward\n",
    "                episode_length += 1\n",
    "                \n",
    "                # Check for safety violations\n",
    "                if info.get('safety_violation', False):\n",
    "                    safety_violation_count += 1\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            episode_rewards.append(total_reward)\n",
    "            episode_lengths.append(episode_length)\n",
    "            \n",
    "            # Calculate battery health improvement\n",
    "            final_soh = obs.get('soh', 1.0)\n",
    "            health_improvement = final_soh - initial_soh\n",
    "            battery_health_improvements.append(health_improvement)\n",
    "            \n",
    "            # Calculate energy efficiency\n",
    "            energy_efficiency = info.get('energy_efficiency', 0.0)\n",
    "            energy_efficiency_scores.append(energy_efficiency)\n",
    "            \n",
    "            safety_violations.append(safety_violation_count)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(episode_rewards),\n",
    "            'std_reward': np.std(episode_rewards),\n",
    "            'mean_episode_length': np.mean(episode_lengths),\n",
    "            'mean_battery_health_improvement': np.mean(battery_health_improvements),\n",
    "            'mean_energy_efficiency': np.mean(energy_efficiency_scores),\n",
    "            'safety_violation_rate': np.mean(safety_violations) / np.mean(episode_lengths),\n",
    "            'success_rate': np.mean([r > 0 for r in episode_rewards])\n",
    "        }\n",
    "    \n",
    "    def objective(self, trial: optuna.Trial) -> float:\n",
    "        \"\"\"\n",
    "        Objective function for hyperparameter optimization.\n",
    "        \n",
    "        Args:\n",
    "            trial: Optuna trial object\n",
    "            \n",
    "        Returns:\n",
    "            Objective value (performance metric)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Select algorithm and environment\n",
    "            algorithm = trial.suggest_categorical('algorithm', self.config['algorithms'])\n",
    "            env_name = trial.suggest_categorical('environment', self.config['environments'])\n",
    "            \n",
    "            # Create environment\n",
    "            env = self.env_generators[env_name]()\n",
    "            \n",
    "            # Suggest hyperparameters\n",
    "            params = self.suggest_hyperparameters(trial, algorithm)\n",
    "            \n",
    "            # Create algorithm instance\n",
    "            agent = self.create_algorithm(algorithm, params, env)\n",
    "            \n",
    "            # Train agent\n",
    "            trainer = RLTrainer(agent, env)\n",
    "            training_metrics = trainer.train(\n",
    "                max_steps=self.config['max_training_steps'],\n",
    "                early_stopping_patience=self.config['early_stopping_patience']\n",
    "            )\n",
    "            \n",
    "            # Evaluate agent\n",
    "            eval_metrics = self.evaluate_agent(agent, env, self.config['evaluation_episodes'])\n",
    "            \n",
    "            # Calculate composite objective score\n",
    "            objective_score = self._calculate_objective_score(eval_metrics, training_metrics)\n",
    "            \n",
    "            # Store trial results\n",
    "            trial_result = {\n",
    "                'trial_number': trial.number,\n",
    "                'algorithm': algorithm,\n",
    "                'environment': env_name,\n",
    "                'params': params,\n",
    "                'eval_metrics': eval_metrics,\n",
    "                'training_metrics': training_metrics,\n",
    "                'objective_score': objective_score\n",
    "            }\n",
    "            \n",
    "            self.results['trials'].append(trial_result)\n",
    "            \n",
    "            return objective_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Trial {trial.number} failed: {str(e)}\")\n",
    "            return -np.inf\n",
    "    \n",
    "    def _calculate_objective_score(self, eval_metrics: Dict[str, float], \n",
    "                                 training_metrics: Dict[str, float]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate composite objective score from evaluation and training metrics.\n",
    "        \n",
    "        Args:\n",
    "            eval_metrics: Evaluation metrics\n",
    "            training_metrics: Training metrics\n",
    "            \n",
    "        Returns:\n",
    "            Composite objective score\n",
    "        \"\"\"\n",
    "        # Weights for different metrics\n",
    "        weights = {\n",
    "            'mean_reward': 0.3,\n",
    "            'battery_health_improvement': 0.25,\n",
    "            'energy_efficiency': 0.2,\n",
    "            'safety_violation_rate': -0.15,  # Negative weight (penalty)\n",
    "            'success_rate': 0.1,\n",
    "            'training_stability': 0.1\n",
    "        }\n",
    "        \n",
    "        # Normalize metrics to [0, 1] range\n",
    "        normalized_metrics = {}\n",
    "        \n",
    "        # Reward normalization (assuming rewards are in [-1000, 1000] range)\n",
    "        normalized_metrics['mean_reward'] = (eval_metrics['mean_reward'] + 1000) / 2000\n",
    "        \n",
    "        # Battery health improvement (assuming [-0.1, 0.1] range)\n",
    "        normalized_metrics['battery_health_improvement'] = (\n",
    "            eval_metrics['mean_battery_health_improvement'] + 0.1\n",
    "        ) / 0.2\n",
    "        \n",
    "        # Energy efficiency (already in [0, 1] range)\n",
    "        normalized_metrics['energy_efficiency'] = eval_metrics['mean_energy_efficiency']\n",
    "        \n",
    "        # Safety violation rate (invert and normalize)\n",
    "        normalized_metrics['safety_violation_rate'] = 1.0 - min(1.0, eval_metrics['safety_violation_rate'])\n",
    "        \n",
    "        # Success rate (already in [0, 1] range)\n",
    "        normalized_metrics['success_rate'] = eval_metrics['success_rate']\n",
    "        \n",
    "        # Training stability (based on reward variance)\n",
    "        reward_stability = 1.0 / (1.0 + eval_metrics['std_reward'])\n",
    "        normalized_metrics['training_stability'] = reward_stability\n",
    "        \n",
    "        # Calculate weighted sum\n",
    "        objective_score = sum(\n",
    "            weights[metric] * normalized_metrics[metric] \n",
    "            for metric in weights.keys()\n",
    "        )\n",
    "        \n",
    "        return objective_score\n",
    "    \n",
    "    def optimize(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run hyperparameter optimization.\n",
    "        \n",
    "        Returns:\n",
    "            Optimization results\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Starting RL Hyperparameter Optimization\")\n",
    "        print(f\"Configuration: {self.config}\")\n",
    "        print()\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            direction=self.config['optimization_direction'],\n",
    "            study_name=self.config['study_name'],\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        study.optimize(\n",
    "            self.objective,\n",
    "            n_trials=self.config['n_trials'],\n",
    "            n_jobs=self.config['n_jobs'],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        \n",
    "        # Process results\n",
    "        self._process_optimization_results()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def _process_optimization_results(self):\n",
    "        \"\"\"Process optimization results and generate insights.\"\"\"\n",
    "        # Group results by algorithm\n",
    "        algorithm_results = {}\n",
    "        for trial in self.results['trials']:\n",
    "            algorithm = trial['algorithm']\n",
    "            if algorithm not in algorithm_results:\n",
    "                algorithm_results[algorithm] = []\n",
    "            algorithm_results[algorithm].append(trial)\n",
    "        \n",
    "        # Find best parameters for each algorithm\n",
    "        for algorithm, trials in algorithm_results.items():\n",
    "            if trials:\n",
    "                best_trial = max(trials, key=lambda x: x['objective_score'])\n",
    "                self.results['best_params_per_algorithm'][algorithm] = {\n",
    "                    'params': best_trial['params'],\n",
    "                    'performance': best_trial['eval_metrics'],\n",
    "                    'objective_score': best_trial['objective_score']\n",
    "                }\n",
    "        \n",
    "        # Create performance comparison\n",
    "        self.results['performance_comparison'] = {\n",
    "            algorithm: {\n",
    "                'mean_objective_score': np.mean([t['objective_score'] for t in trials]),\n",
    "                'std_objective_score': np.std([t['objective_score'] for t in trials]),\n",
    "                'best_objective_score': max([t['objective_score'] for t in trials]),\n",
    "                'num_trials': len(trials)\n",
    "            }\n",
    "            for algorithm, trials in algorithm_results.items() if trials\n",
    "        }\n",
    "    \n",
    "    def visualize_results(self):\n",
    "        \"\"\"Create comprehensive visualization of optimization results.\"\"\"\n",
    "        if not self.study:\n",
    "            print(\"‚ùå No optimization results to visualize. Run optimization first.\")\n",
    "            return\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "        fig.suptitle('üîã BatteryMind RL Hyperparameter Optimization Results', fontsize=16)\n",
    "        \n",
    "        # Plot 1: Optimization history\n",
    "        ax1 = axes[0, 0]\n",
    "        plot_optimization_history(self.study, ax=ax1)\n",
    "        ax1.set_title('Optimization History')\n",
    "        ax1.set_xlabel('Trial')\n",
    "        ax1.set_ylabel('Objective Value')\n",
    "        \n",
    "        # Plot 2: Parameter importance\n",
    "        ax2 = axes[0, 1]\n",
    "        plot_param_importances(self.study, ax=ax2)\n",
    "        ax2.set_title('Parameter Importance')\n",
    "        \n",
    "        # Plot 3: Algorithm comparison\n",
    "        ax3 = axes[0, 2]\n",
    "        algorithms = list(self.results['performance_comparison'].keys())\n",
    "        scores = [self.results['performance_comparison'][alg]['mean_objective_score'] \n",
    "                 for alg in algorithms]\n",
    "        errors = [self.results['performance_comparison'][alg]['std_objective_score'] \n",
    "                 for alg in algorithms]\n",
    "        \n",
    "        bars = ax3.bar(algorithms, scores, yerr=errors, capsize=5)\n",
    "        ax3.set_title('Algorithm Performance Comparison')\n",
    "        ax3.set_ylabel('Mean Objective Score')\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, score in zip(bars, scores):\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{score:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 4: Trial distribution by algorithm\n",
    "        ax4 = axes[1, 0]\n",
    "        trial_counts = [self.results['performance_comparison'][alg]['num_trials'] \n",
    "                       for alg in algorithms]\n",
    "        \n",
    "        ax4.pie(trial_counts, labels=algorithms, autopct='%1.1f%%', startangle=90)\n",
    "        ax4.set_title('Trial Distribution by Algorithm')\n",
    "        \n",
    "        # Plot 5: Performance metrics heatmap\n",
    "        ax5 = axes[1, 1]\n",
    "        metrics_data = []\n",
    "        metric_names = ['mean_reward', 'battery_health_improvement', 'energy_efficiency', \n",
    "                       'safety_violation_rate', 'success_rate']\n",
    "        \n",
    "        for algorithm in algorithms:\n",
    "            best_params = self.results['best_params_per_algorithm'][algorithm]\n",
    "            metrics_row = []\n",
    "            for metric in metric_names:\n",
    "                if metric == 'safety_violation_rate':\n",
    "                    # Invert safety violation rate for better visualization\n",
    "                    metrics_row.append(1.0 - best_params['performance'][metric])\n",
    "                else:\n",
    "                    metrics_row.append(best_params['performance'][metric])\n",
    "            metrics_data.append(metrics_row)\n",
    "        \n",
    "        im = ax5.imshow(metrics_data, cmap='RdYlGn', aspect='auto')\n",
    "        ax5.set_xticks(range(len(metric_names)))\n",
    "        ax5.set_xticklabels(metric_names, rotation=45, ha='right')\n",
    "        ax5.set_yticks(range(len(algorithms)))\n",
    "        ax5.set_yticklabels(algorithms)\n",
    "        ax5.set_title('Performance Metrics Heatmap')\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=ax5, shrink=0.8)\n",
    "        \n",
    "        # Plot 6: Hyperparameter correlation\n",
    "        ax6 = axes[1, 2]\n",
    "        # Extract numerical hyperparameters for correlation analysis\n",
    "        param_data = []\n",
    "        param_names = []\n",
    "        \n",
    "        for trial in self.results['trials']:\n",
    "            if trial['objective_score'] > -np.inf:\n",
    "                row = []\n",
    "                for param, value in trial['params'].items():\n",
    "                    if isinstance(value, (int, float)) and param != 'network_arch':\n",
    "                        if param not in param_names:\n",
    "                            param_names.append(param)\n",
    "                        row.append(value)\n",
    "                \n",
    "                if len(row) == len(param_names):\n",
    "                    param_data.append(row)\n",
    "        \n",
    "        if param_data and len(param_names) > 1:\n",
    "            param_df = pd.DataFrame(param_data, columns=param_names)\n",
    "            corr_matrix = param_df.corr()\n",
    "            \n",
    "            im = ax6.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "            ax6.set_xticks(range(len(param_names)))\n",
    "            ax6.set_xticklabels(param_names, rotation=45, ha='right')\n",
    "            ax6.set_yticks(range(len(param_names)))\n",
    "            ax6.set_yticklabels(param_names)\n",
    "            ax6.set_title('Hyperparameter Correlation')\n",
    "            \n",
    "            # Add correlation values\n",
    "            for i in range(len(param_names)):\n",
    "                for j in range(len(param_names)):\n",
    "                    text = ax6.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                                   ha=\"center\", va=\"center\", color=\"black\")\n",
    "            \n",
    "            plt.colorbar(im, ax=ax6, shrink=0.8)\n",
    "        else:\n",
    "            ax6.text(0.5, 0.5, 'Insufficient data for correlation analysis', \n",
    "                    ha='center', va='center', transform=ax6.transAxes)\n",
    "            ax6.set_title('Hyperparameter Correlation')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"Generate comprehensive optimization report.\"\"\"\n",
    "        if not self.results['trials']:\n",
    "            return \"‚ùå No optimization results available. Run optimization first.\"\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"üîã BatteryMind RL Hyperparameter Optimization Report\")\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(f\"Total trials: {len(self.results['trials'])}\")\n",
    "        report.append(f\"Best objective score: {self.study.best_value:.4f}\")\n",
    "        report.append()\n",
    "        \n",
    "        # Algorithm performance summary\n",
    "        report.append(\"üìä Algorithm Performance Summary\")\n",
    "        report.append(\"-\" * 40)\n",
    "        performance_data = []\n",
    "        \n",
    "        for algorithm, perf in self.results['performance_comparison'].items():\n",
    "            performance_data.append([\n",
    "                algorithm,\n",
    "                f\"{perf['mean_objective_score']:.4f}\",\n",
    "                f\"{perf['std_objective_score']:.4f}\",\n",
    "                f\"{perf['best_objective_score']:.4f}\",\n",
    "                str(perf['num_trials'])\n",
    "            ])\n",
    "        \n",
    "        # Create performance table\n",
    "        headers = ['Algorithm', 'Mean Score', 'Std Score', 'Best Score', 'Trials']\n",
    "        col_widths = [max(len(str(row[i])) for row in [headers] + performance_data) \n",
    "                     for i in range(len(headers))]\n",
    "        \n",
    "        # Print table header\n",
    "        header_row = \" | \".join(headers[i].ljust(col_widths[i]) for i in range(len(headers)))\n",
    "        report.append(header_row)\n",
    "        report.append(\"-\" * len(header_row))\n",
    "        \n",
    "        # Print table rows\n",
    "        for row in performance_data:\n",
    "            data_row = \" | \".join(str(row[i]).ljust(col_widths[i]) for i in range(len(row)))\n",
    "            report.append(data_row)\n",
    "        \n",
    "        report.append()\n",
    "        \n",
    "        # Best parameters for each algorithm\n",
    "        report.append(\"üèÜ Best Parameters by Algorithm\")\n",
    "        report.append(\"-\" * 40)\n",
    "        \n",
    "        for algorithm, best_data in self.results['best_params_per_algorithm'].items():\n",
    "            report.append(f\"\\n{algorithm}:\")\n",
    "            report.append(f\"  Objective Score: {best_data['objective_score']:.4f}\")\n",
    "            report.append(f\"  Mean Reward: {best_data['performance']['mean_reward']:.2f}\")\n",
    "            report.append(f\"  Battery Health Improvement: {best_data['performance']['mean_battery_health_improvement']:.4f}\")\n",
    "            report.append(f\"  Energy Efficiency: {best_data['performance']['mean_energy_efficiency']:.4f}\")\n",
    "            report.append(f\"  Safety Violation Rate: {best_data['performance']['safety_violation_rate']:.4f}\")\n",
    "            report.append(f\"  Success Rate: {best_data['performance']['success_rate']:.4f}\")\n",
    "            \n",
    "            report.append(\"  Key Hyperparameters:\")\n",
    "            for param, value in best_data['params'].items():\n",
    "                if param != 'network_arch':\n",
    "                    report.append(f\"    {param}: {value}\")\n",
    "        \n",
    "        report.append()\n",
    "        \n",
    "        # Optimization insights\n",
    "        report.append(\"üí° Optimization Insights\")\n",
    "        report.append(\"-\" * 40)\n",
    "        \n",
    "        # Best performing algorithm\n",
    "        best_algorithm = max(self.results['performance_comparison'].keys(),\n",
    "                           key=lambda x: self.results['performance_comparison'][x]['best_objective_score'])\n",
    "        report.append(f\"‚Ä¢ Best performing algorithm: {best_algorithm}\")\n",
    "        \n",
    "        # Parameter importance (if available)\n",
    "        if self.study:\n",
    "            importances = optuna.importance.get_param_importances(self.study)\n",
    "            if importances:\n",
    "                report.append(\"‚Ä¢ Most important hyperparameters:\")\n",
    "                for param, importance in list(importances.items())[:5]:\n",
    "                    report.append(f\"  - {param}: {importance:.4f}\")\n",
    "        \n",
    "        report.append()\n",
    "        \n",
    "        # Recommendations\n",
    "        report.append(\"üéØ Recommendations\")\n",
    "        report.append(\"-\" * 40)\n",
    "        report.append(f\"‚Ä¢ Use {best_algorithm} algorithm for best performance\")\n",
    "        report.append(\"‚Ä¢ Focus on tuning the most important hyperparameters\")\n",
    "        report.append(\"‚Ä¢ Consider ensemble methods combining top algorithms\")\n",
    "        report.append(\"‚Ä¢ Validate results on real-world battery data\")\n",
    "        report.append(\"‚Ä¢ Monitor safety constraints in production deployment\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def save_results(self, filepath: str):\n",
    "        \"\"\"Save optimization results to file.\"\"\"\n",
    "        # Prepare serializable results\n",
    "        serializable_results = {\n",
    "            'config': self.config,\n",
    "            'best_params': self.best_params,\n",
    "            'results': self.results,\n",
    "            'study_trials': [\n",
    "                {\n",
    "                    'number': trial.number,\n",
    "                    'value': trial.value,\n",
    "                    'params': trial.params,\n",
    "                    'state': trial.state.name\n",
    "                }\n",
    "                for trial in self.study.trials\n",
    "            ] if self.study else []\n",
    "        }\n",
    "        \n",
    "        # Save to JSON\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"‚úÖ Results saved to {filepath}\")\n",
    "\n",
    "# Initialize and run optimization\n",
    "print(\"üîß Initializing RL Hyperparameter Optimizer...\")\n",
    "optimizer = RLHyperparameterOptimizer(OPTIMIZATION_CONFIG)\n",
    "\n",
    "# Run optimization\n",
    "print(\"üöÄ Starting optimization process...\")\n",
    "results = optimizer.optimize()\n",
    "\n",
    "# Generate and display report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(optimizer.generate_report())\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize results\n",
    "print(\"\\nüìä Generating visualization...\")\n",
    "optimizer.visualize_results()\n",
    "\n",
    "# Save results\n",
    "results_filename = f\"rl_hyperparameter_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "optimizer.save_results(results_filename)\n",
    "\n",
    "print(f\"\\n‚úÖ Hyperparameter optimization completed!\")\n",
    "print(f\"üìÅ Results saved to: {results_filename}\")\n",
    "print(f\"üèÜ Best algorithm: {max(results['performance_comparison'].keys(), key=lambda x: results['performance_comparison'][x]['best_objective_score'])}\")\n",
    "print(f\"üéØ Best objective score: {optimizer.study.best_value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
