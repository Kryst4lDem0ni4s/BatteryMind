{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb3ade",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BatteryMind - Transformer Hyperparameter Tuning\n",
    "\n",
    "Advanced hyperparameter optimization for transformer-based battery health prediction models.\n",
    "This notebook provides comprehensive tuning capabilities using Optuna, Ray Tune, and custom \n",
    "optimization strategies specifically designed for battery domain applications.\n",
    "\n",
    "Features:\n",
    "- Multi-objective optimization for accuracy and efficiency\n",
    "- Bayesian optimization with domain-specific priors\n",
    "- Automated hyperparameter search with early stopping\n",
    "- Resource-aware optimization for different hardware constraints\n",
    "- Integration with distributed training frameworks\n",
    "- Custom battery-specific evaluation metrics\n",
    "\n",
    "Author: BatteryMind Development Team\n",
    "Version: 1.0.0\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import logging\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optimization libraries\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner, HyperbandPruner\n",
    "from optuna.samplers import TPESampler, CmaEsSampler\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.tune.suggest.optuna import OptunaSearch\n",
    "\n",
    "# ML libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "# Transformers and custom modules\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "# BatteryMind specific imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from transformers.battery_health_predictor.model import BatteryHealthTransformer\n",
    "from transformers.battery_health_predictor.trainer import BatteryTransformerTrainer\n",
    "from transformers.battery_health_predictor.data_loader import BatteryDataLoader\n",
    "from transformers.battery_health_predictor.preprocessing import BatteryDataPreprocessor\n",
    "from training_data.synthetic_datasets import generate_battery_telemetry_data\n",
    "from evaluation.metrics.accuracy_metrics import BatteryHealthMetrics\n",
    "from utils.config_parser import ConfigParser\n",
    "from utils.logging_utils import setup_logging\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging(__name__)\n",
    "\n",
    "class BatteryTransformerOptimizer:\n",
    "    \"\"\"\n",
    "    Advanced hyperparameter optimizer for battery transformer models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_config: Dict[str, Any],\n",
    "                 base_model_config: Dict[str, Any],\n",
    "                 optimization_config: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Initialize the optimizer with configurations.\n",
    "        \n",
    "        Args:\n",
    "            data_config: Configuration for data loading and preprocessing\n",
    "            base_model_config: Base model configuration\n",
    "            optimization_config: Optimization-specific configuration\n",
    "        \"\"\"\n",
    "        self.data_config = data_config\n",
    "        self.base_model_config = base_model_config\n",
    "        self.optimization_config = optimization_config\n",
    "        \n",
    "        # Initialize data components\n",
    "        self.data_loader = BatteryDataLoader(data_config)\n",
    "        self.preprocessor = BatteryDataPreprocessor(data_config)\n",
    "        self.metrics = BatteryHealthMetrics()\n",
    "        \n",
    "        # Load datasets\n",
    "        self.train_data, self.val_data, self.test_data = self._load_datasets()\n",
    "        \n",
    "        # Optimization tracking\n",
    "        self.best_params = None\n",
    "        self.best_score = float('-inf')\n",
    "        self.optimization_history = []\n",
    "        \n",
    "        logger.info(\"BatteryTransformerOptimizer initialized\")\n",
    "    \n",
    "    def _load_datasets(self) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "        \"\"\"Load and preprocess datasets for optimization.\"\"\"\n",
    "        # Generate synthetic data for optimization\n",
    "        logger.info(\"Loading datasets for hyperparameter optimization...\")\n",
    "        \n",
    "        # Load training data\n",
    "        train_df = generate_battery_telemetry_data(\n",
    "            num_batteries=self.data_config.get('num_batteries', 100),\n",
    "            duration_days=self.data_config.get('duration_days', 30)\n",
    "        )\n",
    "        \n",
    "        # Preprocess data\n",
    "        train_processed = self.preprocessor.preprocess(train_df)\n",
    "        \n",
    "        # Create train/validation/test splits\n",
    "        train_size = int(0.7 * len(train_processed))\n",
    "        val_size = int(0.2 * len(train_processed))\n",
    "        \n",
    "        train_data = train_processed[:train_size]\n",
    "        val_data = train_processed[train_size:train_size + val_size]\n",
    "        test_data = train_processed[train_size + val_size:]\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    def _create_model_with_params(self, trial_params: Dict[str, Any]) -> BatteryHealthTransformer:\n",
    "        \"\"\"Create model with trial parameters.\"\"\"\n",
    "        model_config = self.base_model_config.copy()\n",
    "        model_config.update(trial_params)\n",
    "        \n",
    "        return BatteryHealthTransformer(\n",
    "            config=model_config,\n",
    "            num_features=self.data_config['num_features'],\n",
    "            num_classes=self.data_config['num_classes']\n",
    "        )\n",
    "    \n",
    "    def _objective_function(self, trial) -> float:\n",
    "        \"\"\"\n",
    "        Objective function for Optuna optimization.\n",
    "        \n",
    "        Args:\n",
    "            trial: Optuna trial object\n",
    "            \n",
    "        Returns:\n",
    "            float: Objective value to maximize\n",
    "        \"\"\"\n",
    "        # Sample hyperparameters\n",
    "        params = {\n",
    "            # Architecture parameters\n",
    "            'hidden_size': trial.suggest_categorical('hidden_size', [256, 512, 768, 1024]),\n",
    "            'num_attention_heads': trial.suggest_categorical('num_attention_heads', [4, 8, 12, 16]),\n",
    "            'num_hidden_layers': trial.suggest_int('num_hidden_layers', 6, 24),\n",
    "            'intermediate_size': trial.suggest_categorical('intermediate_size', [1024, 2048, 3072, 4096]),\n",
    "            \n",
    "            # Training parameters\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-3, log=True),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-1, log=True),\n",
    "            'dropout_rate': trial.suggest_float('dropout_rate', 0.0, 0.5),\n",
    "            'attention_dropout': trial.suggest_float('attention_dropout', 0.0, 0.3),\n",
    "            \n",
    "            # Regularization parameters\n",
    "            'label_smoothing': trial.suggest_float('label_smoothing', 0.0, 0.2),\n",
    "            'warmup_steps': trial.suggest_int('warmup_steps', 100, 2000),\n",
    "            \n",
    "            # Optimization parameters\n",
    "            'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64, 128]),\n",
    "            'gradient_accumulation_steps': trial.suggest_categorical('gradient_accumulation_steps', [1, 2, 4, 8]),\n",
    "            'max_grad_norm': trial.suggest_float('max_grad_norm', 0.1, 2.0),\n",
    "            \n",
    "            # Scheduler parameters\n",
    "            'scheduler_type': trial.suggest_categorical('scheduler_type', ['linear', 'cosine', 'polynomial']),\n",
    "            'num_cycles': trial.suggest_int('num_cycles', 1, 3) if params.get('scheduler_type') == 'cosine' else 1,\n",
    "        }\n",
    "        \n",
    "        # Ensure architectural constraints\n",
    "        if params['hidden_size'] % params['num_attention_heads'] != 0:\n",
    "            params['num_attention_heads'] = self._find_valid_heads(params['hidden_size'])\n",
    "        \n",
    "        try:\n",
    "            # Create model\n",
    "            model = self._create_model_with_params(params)\n",
    "            \n",
    "            # Setup trainer\n",
    "            trainer = BatteryTransformerTrainer(\n",
    "                model=model,\n",
    "                train_data=self.train_data,\n",
    "                val_data=self.val_data,\n",
    "                training_config=params,\n",
    "                callbacks=[\n",
    "                    PyTorchLightningPruningCallback(trial, monitor='val_loss')\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Train model\n",
    "            trainer.fit(max_epochs=self.optimization_config.get('max_epochs', 50))\n",
    "            \n",
    "            # Evaluate model\n",
    "            val_metrics = trainer.validate()\n",
    "            \n",
    "            # Calculate composite score\n",
    "            composite_score = self._calculate_composite_score(val_metrics, params)\n",
    "            \n",
    "            # Store trial results\n",
    "            trial_result = {\n",
    "                'trial_number': trial.number,\n",
    "                'params': params,\n",
    "                'score': composite_score,\n",
    "                'metrics': val_metrics,\n",
    "                'model_size_mb': self._calculate_model_size(model),\n",
    "                'training_time_minutes': trainer.get_training_time()\n",
    "            }\n",
    "            \n",
    "            self.optimization_history.append(trial_result)\n",
    "            \n",
    "            # Update best parameters\n",
    "            if composite_score > self.best_score:\n",
    "                self.best_score = composite_score\n",
    "                self.best_params = params.copy()\n",
    "                \n",
    "                # Save best model\n",
    "                self._save_best_model(model, params, val_metrics)\n",
    "            \n",
    "            return composite_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Trial {trial.number} failed: {str(e)}\")\n",
    "            return float('-inf')\n",
    "    \n",
    "    def _find_valid_heads(self, hidden_size: int) -> int:\n",
    "        \"\"\"Find valid number of attention heads for given hidden size.\"\"\"\n",
    "        valid_heads = [h for h in [4, 8, 12, 16] if hidden_size % h == 0]\n",
    "        return valid_heads[0] if valid_heads else 8\n",
    "    \n",
    "    def _calculate_composite_score(self, metrics: Dict[str, float], params: Dict[str, Any]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate composite score considering multiple objectives.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Validation metrics\n",
    "            params: Model parameters\n",
    "            \n",
    "        Returns:\n",
    "            float: Composite score\n",
    "        \"\"\"\n",
    "        # Primary metrics (accuracy-based)\n",
    "        accuracy_score = metrics.get('soh_accuracy', 0) * 0.3\n",
    "        mae_score = max(0, 1 - metrics.get('soh_mae', 1)) * 0.25\n",
    "        rul_accuracy = metrics.get('rul_accuracy_within_10_percent', 0) * 0.2\n",
    "        anomaly_f1 = metrics.get('anomaly_f1', 0) * 0.15\n",
    "        \n",
    "        # Secondary metrics (efficiency-based)\n",
    "        model_size_penalty = max(0, 1 - params.get('model_size_mb', 1000) / 1000) * 0.05\n",
    "        inference_speed_bonus = max(0, 1 - metrics.get('inference_time_ms', 100) / 100) * 0.05\n",
    "        \n",
    "        composite_score = (\n",
    "            accuracy_score + mae_score + rul_accuracy + anomaly_f1 + \n",
    "            model_size_penalty + inference_speed_bonus\n",
    "        )\n",
    "        \n",
    "        return composite_score\n",
    "    \n",
    "    def _calculate_model_size(self, model) -> float:\n",
    "        \"\"\"Calculate model size in MB.\"\"\"\n",
    "        param_size = sum(p.numel() for p in model.parameters())\n",
    "        buffer_size = sum(b.numel() for b in model.buffers())\n",
    "        size_mb = (param_size + buffer_size) * 4 / (1024 * 1024)  # 4 bytes per float32\n",
    "        return size_mb\n",
    "    \n",
    "    def _save_best_model(self, model, params: Dict[str, Any], metrics: Dict[str, float]):\n",
    "        \"\"\"Save the best model and its configuration.\"\"\"\n",
    "        save_dir = Path(\"../../model-artifacts/hyperparameter_tuning/transformer_best\")\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), save_dir / \"best_model.pt\")\n",
    "        \n",
    "        # Save configuration\n",
    "        config = {\n",
    "            'parameters': params,\n",
    "            'metrics': metrics,\n",
    "            'model_size_mb': self._calculate_model_size(model),\n",
    "            'optimization_timestamp': pd.Timestamp.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(save_dir / \"best_config.json\", 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Best model saved with score: {self.best_score:.4f}\")\n",
    "    \n",
    "    def optimize_with_optuna(self, n_trials: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Optimize hyperparameters using Optuna.\n",
    "        \n",
    "        Args:\n",
    "            n_trials: Number of optimization trials\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing optimization results\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting Optuna optimization with {n_trials} trials\")\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42),\n",
    "            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "        )\n",
    "        \n",
    "        # Add battery-specific constraints\n",
    "        study.enqueue_trial({\n",
    "            'hidden_size': 768,\n",
    "            'num_attention_heads': 12,\n",
    "            'num_hidden_layers': 12,\n",
    "            'learning_rate': 2e-5,\n",
    "            'batch_size': 32\n",
    "        })\n",
    "        \n",
    "        # Optimize\n",
    "        study.optimize(\n",
    "            self._objective_function,\n",
    "            n_trials=n_trials,\n",
    "            timeout=self.optimization_config.get('timeout_hours', 24) * 3600,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        # Compile results\n",
    "        results = {\n",
    "            'best_params': study.best_params,\n",
    "            'best_score': study.best_value,\n",
    "            'n_trials': len(study.trials),\n",
    "            'optimization_history': self.optimization_history,\n",
    "            'study_statistics': self._get_study_statistics(study)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Optuna optimization completed. Best score: {study.best_value:.4f}\")\n",
    "        return results\n",
    "    \n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Callback for Optuna optimization.\"\"\"\n",
    "        if trial.number % 10 == 0:\n",
    "            logger.info(f\"Trial {trial.number}: Current best score = {study.best_value:.4f}\")\n",
    "    \n",
    "    def _get_study_statistics(self, study) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive study statistics.\"\"\"\n",
    "        df = study.trials_dataframe()\n",
    "        \n",
    "        return {\n",
    "            'total_trials': len(study.trials),\n",
    "            'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n",
    "            'failed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n",
    "            'pruned_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n",
    "            'best_trial_number': study.best_trial.number,\n",
    "            'optimization_duration_hours': (study.trials[-1].datetime_complete - study.trials[0].datetime_start).total_seconds() / 3600,\n",
    "            'parameter_importance': optuna.importance.get_param_importances(study) if len(study.trials) > 10 else {}\n",
    "        }\n",
    "    \n",
    "    def optimize_with_ray_tune(self, n_trials: int = 50) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Optimize hyperparameters using Ray Tune.\n",
    "        \n",
    "        Args:\n",
    "            n_trials: Number of optimization trials\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing optimization results\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting Ray Tune optimization with {n_trials} trials\")\n",
    "        \n",
    "        # Initialize Ray\n",
    "        ray.init(ignore_reinit_error=True)\n",
    "        \n",
    "        # Define search space\n",
    "        search_space = {\n",
    "            'hidden_size': tune.choice([256, 512, 768, 1024]),\n",
    "            'num_attention_heads': tune.choice([4, 8, 12, 16]),\n",
    "            'num_hidden_layers': tune.randint(6, 24),\n",
    "            'learning_rate': tune.loguniform(1e-6, 1e-3),\n",
    "            'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "            'dropout_rate': tune.uniform(0.0, 0.5),\n",
    "            'batch_size': tune.choice([16, 32, 64, 128]),\n",
    "            'warmup_steps': tune.randint(100, 2000)\n",
    "        }\n",
    "        \n",
    "        # Setup scheduler\n",
    "        scheduler = ASHAScheduler(\n",
    "            max_t=self.optimization_config.get('max_epochs', 50),\n",
    "            grace_period=5,\n",
    "            reduction_factor=2\n",
    "        )\n",
    "        \n",
    "        # Setup search algorithm\n",
    "        search_alg = OptunaSearch(\n",
    "            sampler=TPESampler(seed=42),\n",
    "            metric='score',\n",
    "            mode='max'\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        analysis = tune.run(\n",
    "            self._ray_tune_trainable,\n",
    "            config=search_space,\n",
    "            num_samples=n_trials,\n",
    "            scheduler=scheduler,\n",
    "            search_alg=search_alg,\n",
    "            resources_per_trial={'cpu': 4, 'gpu': 1},\n",
    "            local_dir='./ray_results',\n",
    "            name='battery_transformer_tuning'\n",
    "        )\n",
    "        \n",
    "        # Get best result\n",
    "        best_trial = analysis.get_best_trial('score', 'max')\n",
    "        \n",
    "        results = {\n",
    "            'best_params': best_trial.config,\n",
    "            'best_score': best_trial.metric_analysis['score']['last'],\n",
    "            'n_trials': n_trials,\n",
    "            'best_trial_path': best_trial.checkpoint.value,\n",
    "            'analysis': analysis\n",
    "        }\n",
    "        \n",
    "        ray.shutdown()\n",
    "        logger.info(f\"Ray Tune optimization completed. Best score: {results['best_score']:.4f}\")\n",
    "        return results\n",
    "    \n",
    "    def _ray_tune_trainable(self, config):\n",
    "        \"\"\"Trainable function for Ray Tune.\"\"\"\n",
    "        # Create model with config\n",
    "        model = self._create_model_with_params(config)\n",
    "        \n",
    "        # Setup trainer\n",
    "        trainer = BatteryTransformerTrainer(\n",
    "            model=model,\n",
    "            train_data=self.train_data,\n",
    "            val_data=self.val_data,\n",
    "            training_config=config\n",
    "        )\n",
    "        \n",
    "        # Train with reporting\n",
    "        for epoch in range(self.optimization_config.get('max_epochs', 50)):\n",
    "            trainer.train_epoch()\n",
    "            val_metrics = trainer.validate()\n",
    "            \n",
    "            score = self._calculate_composite_score(val_metrics, config)\n",
    "            \n",
    "            # Report to Ray Tune\n",
    "            tune.report(score=score, **val_metrics)\n",
    "    \n",
    "    def analyze_optimization_results(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze optimization results and provide insights.\n",
    "        \n",
    "        Args:\n",
    "            results: Optimization results\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing analysis results\n",
    "        \"\"\"\n",
    "        logger.info(\"Analyzing optimization results...\")\n",
    "        \n",
    "        # Parameter importance analysis\n",
    "        param_importance = self._analyze_parameter_importance()\n",
    "        \n",
    "        # Performance trends\n",
    "        performance_trends = self._analyze_performance_trends()\n",
    "        \n",
    "        # Resource utilization\n",
    "        resource_analysis = self._analyze_resource_utilization()\n",
    "        \n",
    "        # Recommendations\n",
    "        recommendations = self._generate_recommendations()\n",
    "        \n",
    "        analysis = {\n",
    "            'parameter_importance': param_importance,\n",
    "            'performance_trends': performance_trends,\n",
    "            'resource_analysis': resource_analysis,\n",
    "            'recommendations': recommendations,\n",
    "            'best_configuration': {\n",
    "                'parameters': self.best_params,\n",
    "                'score': self.best_score,\n",
    "                'expected_performance': self._predict_performance(self.best_params)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_parameter_importance(self) -> Dict[str, float]:\n",
    "        \"\"\"Analyze parameter importance from optimization history.\"\"\"\n",
    "        if not self.optimization_history:\n",
    "            return {}\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(self.optimization_history)\n",
    "        \n",
    "        # Calculate correlation with score\n",
    "        param_importance = {}\n",
    "        for param in ['hidden_size', 'num_attention_heads', 'learning_rate', 'dropout_rate']:\n",
    "            if param in df.columns:\n",
    "                correlation = df[param].corr(df['score'])\n",
    "                param_importance[param] = abs(correlation)\n",
    "        \n",
    "        return param_importance\n",
    "    \n",
    "    def _analyze_performance_trends(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze performance trends across trials.\"\"\"\n",
    "        if not self.optimization_history:\n",
    "            return {}\n",
    "        \n",
    "        df = pd.DataFrame(self.optimization_history)\n",
    "        \n",
    "        return {\n",
    "            'score_progression': df['score'].tolist(),\n",
    "            'best_score_progression': df['score'].cummax().tolist(),\n",
    "            'convergence_rate': self._calculate_convergence_rate(df['score']),\n",
    "            'optimization_efficiency': len(df[df['score'] > df['score'].quantile(0.9)]) / len(df)\n",
    "        }\n",
    "    \n",
    "    def _analyze_resource_utilization(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze resource utilization patterns.\"\"\"\n",
    "        if not self.optimization_history:\n",
    "            return {}\n",
    "        \n",
    "        df = pd.DataFrame(self.optimization_history)\n",
    "        \n",
    "        return {\n",
    "            'average_model_size_mb': df['model_size_mb'].mean(),\n",
    "            'average_training_time_minutes': df['training_time_minutes'].mean(),\n",
    "            'size_performance_tradeoff': df['model_size_mb'].corr(df['score']),\n",
    "            'time_performance_tradeoff': df['training_time_minutes'].corr(df['score'])\n",
    "        }\n",
    "    \n",
    "    def _generate_recommendations(self) -> List[str]:\n",
    "        \"\"\"Generate optimization recommendations.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if self.best_params:\n",
    "            # Architecture recommendations\n",
    "            if self.best_params['hidden_size'] >= 768:\n",
    "                recommendations.append(\"Large hidden size (â‰¥768) performs well for battery data\")\n",
    "            \n",
    "            if self.best_params['num_hidden_layers'] >= 12:\n",
    "                recommendations.append(\"Deep architectures (â‰¥12 layers) capture complex temporal patterns\")\n",
    "            \n",
    "            # Training recommendations\n",
    "            if self.best_params['learning_rate'] <= 5e-5:\n",
    "                recommendations.append(\"Lower learning rates (â‰¤5e-5) provide better stability\")\n",
    "            \n",
    "            if self.best_params['dropout_rate'] <= 0.2:\n",
    "                recommendations.append(\"Conservative dropout (â‰¤0.2) prevents overfitting\")\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _calculate_convergence_rate(self, scores: pd.Series) -> float:\n",
    "        \"\"\"Calculate convergence rate of optimization.\"\"\"\n",
    "        if len(scores) < 10:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate moving average\n",
    "        window = min(10, len(scores) // 4)\n",
    "        moving_avg = scores.rolling(window=window).mean()\n",
    "        \n",
    "        # Calculate convergence as stability of moving average\n",
    "        convergence_rate = 1.0 - moving_avg.std() / moving_avg.mean()\n",
    "        return max(0.0, convergence_rate)\n",
    "    \n",
    "    def _predict_performance(self, params: Dict[str, Any]) -> Dict[str, float]:\n",
    "        \"\"\"Predict performance metrics for given parameters.\"\"\"\n",
    "        # Simple heuristic-based prediction\n",
    "        base_accuracy = 0.85\n",
    "        \n",
    "        # Adjust based on architecture\n",
    "        if params['hidden_size'] >= 768:\n",
    "            base_accuracy += 0.05\n",
    "        if params['num_hidden_layers'] >= 12:\n",
    "            base_accuracy += 0.03\n",
    "        \n",
    "        # Adjust based on training params\n",
    "        if params['learning_rate'] <= 5e-5:\n",
    "            base_accuracy += 0.02\n",
    "        if params['dropout_rate'] <= 0.2:\n",
    "            base_accuracy += 0.01\n",
    "        \n",
    "        return {\n",
    "            'expected_accuracy': min(0.99, base_accuracy),\n",
    "            'expected_mae': max(0.01, 0.15 - (base_accuracy - 0.85)),\n",
    "            'expected_training_time_hours': params['num_hidden_layers'] * 0.5,\n",
    "            'expected_model_size_mb': params['hidden_size'] * params['num_hidden_layers'] * 0.01\n",
    "        }\n",
    "    \n",
    "    def visualize_optimization_results(self, results: Dict[str, Any]) -> None:\n",
    "        \"\"\"Create visualizations of optimization results.\"\"\"\n",
    "        if not self.optimization_history:\n",
    "            logger.warning(\"No optimization history available for visualization\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(self.optimization_history)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('Transformer Hyperparameter Optimization Results', fontsize=16)\n",
    "        \n",
    "        # 1. Score progression\n",
    "        axes[0, 0].plot(df['trial_number'], df['score'], 'b-', alpha=0.7, label='Trial Score')\n",
    "        axes[0, 0].plot(df['trial_number'], df['score'].cummax(), 'r-', linewidth=2, label='Best Score')\n",
    "        axes[0, 0].set_xlabel('Trial Number')\n",
    "        axes[0, 0].set_ylabel('Composite Score')\n",
    "        axes[0, 0].set_title('Optimization Progress')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Parameter importance\n",
    "        param_importance = self._analyze_parameter_importance()\n",
    "        if param_importance:\n",
    "            params = list(param_importance.keys())\n",
    "            importance = list(param_importance.values())\n",
    "            axes[0, 1].bar(params, importance, color='skyblue')\n",
    "            axes[0, 1].set_xlabel('Parameters')\n",
    "            axes[0, 1].set_ylabel('Importance Score')\n",
    "            axes[0, 1].set_title('Parameter Importance')\n",
    "            axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 3. Score vs Model Size\n",
    "        axes[0, 2].scatter(df['model_size_mb'], df['score'], alpha=0.6)\n",
    "        axes[0, 2].set_xlabel('Model Size (MB)')\n",
    "        axes[0, 2].set_ylabel('Score')\n",
    "        axes[0, 2].set_title('Score vs Model Size')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Learning rate distribution\n",
    "        if 'learning_rate' in df.columns:\n",
    "            axes[1, 0].hist(df['learning_rate'], bins=20, alpha=0.7, color='green')\n",
    "            axes[1, 0].set_xlabel('Learning Rate')\n",
    "            axes[1, 0].set_ylabel('Frequency')\n",
    "            axes[1, 0].set_title('Learning Rate Distribution')\n",
    "            axes[1, 0].set_xscale('log')\n",
    "        \n",
    "        # 5. Hidden size vs Score\n",
    "        if 'hidden_size' in df.columns:\n",
    "            hidden_sizes = df['hidden_size'].unique()\n",
    "            scores_by_size = [df[df['hidden_size'] == size]['score'].mean() for size in hidden_sizes]\n",
    "            axes[1, 1].bar(hidden_sizes, scores_by_size, color='orange')\n",
    "            axes[1, 1].set_xlabel('Hidden Size')\n",
    "            axes[1, 1].set_ylabel('Average Score')\n",
    "            axes[1, 1].set_title('Hidden Size vs Performance')\n",
    "        \n",
    "        # 6. Training time vs Score\n",
    "        if 'training_time_minutes' in df.columns:\n",
    "            axes[1, 2].scatter(df['training_time_minutes'], df['score'], alpha=0.6, color='red')\n",
    "            axes[1, 2].set_xlabel('Training Time (minutes)')\n",
    "            axes[1, 2].set_ylabel('Score')\n",
    "            axes[1, 2].set_title('Training Time vs Performance')\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('transformer_optimization_results.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def export_optimization_report(self, results: Dict[str, Any], \n",
    "                                  filename: str = \"transformer_optimization_report.html\") -> str:\n",
    "        \"\"\"Export comprehensive optimization report.\"\"\"\n",
    "        logger.info(f\"Exporting optimization report to {filename}\")\n",
    "        \n",
    "        # Create HTML report\n",
    "        html_template = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>BatteryMind Transformer Optimization Report</title>\n",
    "            <style>\n",
    "                body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "                .header { background-color: #f0f0f0; padding: 20px; border-radius: 5px; }\n",
    "                .section { margin: 20px 0; padding: 15px; border-left: 4px solid #007acc; }\n",
    "                .metric { display: inline-block; margin: 10px; padding: 10px; background-color: #f9f9f9; border-radius: 3px; }\n",
    "                .recommendation { background-color: #e8f5e8; padding: 10px; margin: 5px 0; border-radius: 3px; }\n",
    "                table { border-collapse: collapse; width: 100%; }\n",
    "                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n",
    "                th { background-color: #f2f2f2; }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"header\">\n",
    "                <h1>BatteryMind Transformer Optimization Report</h1>\n",
    "                <p>Generated on: {timestamp}</p>\n",
    "                <p>Total Trials: {total_trials}</p>\n",
    "                <p>Best Score: {best_score:.4f}</p>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>Best Configuration</h2>\n",
    "                <table>\n",
    "                    <tr><th>Parameter</th><th>Value</th></tr>\n",
    "                    {best_params_table}\n",
    "                </table>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>Performance Analysis</h2>\n",
    "                <div class=\"metric\">\n",
    "                    <strong>Convergence Rate:</strong> {convergence_rate:.3f}\n",
    "                </div>\n",
    "                <div class=\"metric\">\n",
    "                    <strong>Optimization Efficiency:</strong> {optimization_efficiency:.3f}\n",
    "                </div>\n",
    "                <div class=\"metric\">\n",
    "                    <strong>Best Model Size:</strong> {best_model_size:.1f} MB\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>Recommendations</h2>\n",
    "                {recommendations_html}\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>Parameter Importance</h2>\n",
    "                <table>\n",
    "                    <tr><th>Parameter</th><th>Importance</th></tr>\n",
    "                    {param_importance_table}\n",
    "                </table>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare data for template\n",
    "        analysis = self.analyze_optimization_results(results)\n",
    "        \n",
    "        # Best parameters table\n",
    "        best_params_rows = \"\"\n",
    "        if self.best_params:\n",
    "            for param, value in self.best_params.items():\n",
    "                best_params_rows += f\"<tr><td>{param}</td><td>{value}</td></tr>\"\n",
    "        \n",
    "        # Recommendations HTML\n",
    "        recommendations_html = \"\"\n",
    "        for rec in analysis.get('recommendations', []):\n",
    "            recommendations_html += f'<div class=\"recommendation\">{rec}</div>'\n",
    "        \n",
    "        # Parameter importance table\n",
    "        param_importance_rows = \"\"\n",
    "        for param, importance in analysis.get('parameter_importance', {}).items():\n",
    "            param_importance_rows += f\"<tr><td>{param}</td><td>{importance:.3f}</td></tr>\"\n",
    "        \n",
    "        # Fill template\n",
    "        html_content = html_template.format(\n",
    "            timestamp=pd.Timestamp.now().isoformat(),\n",
    "            total_trials=len(self.optimization_history),\n",
    "            best_score=self.best_score,\n",
    "            best_params_table=best_params_rows,\n",
    "            convergence_rate=analysis.get('performance_trends', {}).get('convergence_rate', 0),\n",
    "            optimization_efficiency=analysis.get('performance_trends', {}).get('optimization_efficiency', 0),\n",
    "            best_model_size=analysis.get('resource_analysis', {}).get('average_model_size_mb', 0),\n",
    "            recommendations_html=recommendations_html,\n",
    "            param_importance_table=param_importance_rows\n",
    "        )\n",
    "        \n",
    "        # Save report\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        logger.info(f\"Optimization report saved to {filename}\")\n",
    "        return filename\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    data_config = {\n",
    "        'num_batteries': 200,\n",
    "        'duration_days': 60,\n",
    "        'num_features': 23,\n",
    "        'num_classes': 4,\n",
    "        'sequence_length': 256,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "    \n",
    "    base_model_config = {\n",
    "        'hidden_size': 768,\n",
    "        'num_attention_heads': 12,\n",
    "        'num_hidden_layers': 12,\n",
    "        'max_position_embeddings': 512,\n",
    "        'type_vocab_size': 2\n",
    "    }\n",
    "    \n",
    "    optimization_config = {\n",
    "        'max_epochs': 30,\n",
    "        'timeout_hours': 12,\n",
    "        'n_trials': 100,\n",
    "        'optimization_method': 'optuna'  # or 'ray_tune'\n",
    "    }\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = BatteryTransformerOptimizer(\n",
    "        data_config=data_config,\n",
    "        base_model_config=base_model_config,\n",
    "        optimization_config=optimization_config\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    print(\"ðŸš€ Starting Transformer Hyperparameter Optimization...\")\n",
    "    print(f\"Configuration: {optimization_config['n_trials']} trials, {optimization_config['max_epochs']} epochs\")\n",
    "    \n",
    "    if optimization_config['optimization_method'] == 'optuna':\n",
    "        results = optimizer.optimize_with_optuna(n_trials=optimization_config['n_trials'])\n",
    "    else:\n",
    "        results = optimizer.optimize_with_ray_tune(n_trials=optimization_config['n_trials'])\n",
    "    \n",
    "    # Analyze results\n",
    "    print(\"\\nðŸ“Š Analyzing optimization results...\")\n",
    "    analysis = optimizer.analyze_optimization_results(results)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nðŸŽ¯ Best Score: {optimizer.best_score:.4f}\")\n",
    "    print(f\"ðŸ“‹ Best Parameters:\")\n",
    "    for param, value in optimizer.best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ Recommendations:\")\n",
    "    for rec in analysis['recommendations']:\n",
    "        print(f\"  â€¢ {rec}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"\\nðŸ“ˆ Creating visualizations...\")\n",
    "    optimizer.visualize_optimization_results(results)\n",
    "    \n",
    "    # Export report\n",
    "    print(\"\\nðŸ“„ Exporting optimization report...\")\n",
    "    report_path = optimizer.export_optimization_report(results)\n",
    "    print(f\"Report saved to: {report_path}\")\n",
    "    \n",
    "    print(\"\\nâœ… Transformer hyperparameter optimization completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
